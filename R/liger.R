
#' The LIGER Class
#'
#' The liger object is created from two or more single cell datasets. To construct a
#' liger object, the user needs to provide at least two expression (or another
#' single-cell modality) matrices. The class provides functions for data
#' preprocessing, integrative analysis, and visualization.
#'
#' The key slots used in the liger object are described below.
#'
#' @slot raw.data List of raw data matrices, one per experiment/dataset (genes by cells)
#' @slot norm.data List of normalized matrices (genes by cells)
#' @slot scale.data List of scaled matrices (cells by genes)
#' @slot cell.data Dataframe of cell attributes across all datasets (nrows equal to total number
#'   cells across all datasets)
#' @slot var.genes Subset of informative genes shared across datasets to be used in matrix
#'   factorization
#' @slot H Cell loading factors (one matrix per dataset, dimensions cells by k)
#' @slot H.norm Normalized cell loading factors (cells across all datasets combined into single
#'   matrix)
#' @slot W Shared gene loading factors (k by genes)
#' @slot V Dataset-specific gene loading factors (one matrix per dataset, dimensions k by genes)
#' @slot dr.coords List of 2 matricies of 2D coordinates obtained from running t-SNE or UMAP on H.norm or H matrices
#' @slot alignment.clusters Initial joint cluster assignments from shared factor alignment
#' @slot clusters Joint cluster assignments for cells
#' @slot snf List of values associated with shared nearest factor matrix for use in clustering and
#'   alignment (out.summary contains edge weight information between cell combinations)
#' @slot agg.data Data aggregated within clusters
#' @slot parameters List of parameters used throughout analysis
#' @slot version Version of package used to create object
#'
#' @name liger
#' @rdname liger
#' @aliases liger-class
#' @exportClass liger
#' @importFrom Rcpp evalCpp
#' @useDynLib liger

liger <- methods::setClass(
  "liger",
  slots = c(
    raw.data = "list",
    norm.data = "list",
    scale.data = "list",
    cell.data = "data.frame",
    var.genes = "vector",
    H = "list",
    H.norm = "matrix",
    W = "matrix",
    V = "list",
    dr.coords = "list",
    alignment.clusters = 'factor',
    clusters= "factor",
    agg.data = "list",
    parameters = "list",
    snf = 'list',
    version = 'ANY'
  )
)

#' show method for liger
#'
#' @param object liger object
#' @name show
#' @aliases show,liger-method
#' @docType methods
#' @rdname show-methods

setMethod(
  f = "show",
  signature = "liger",
  definition = function(object) {
    cat(
      "An object of class",
      class(object),
      "\nwith",
      length(object@raw.data),
      "datasets and\n",
      nrow(object@cell.data),
      "total cells."
    )
    invisible(x = NULL)
  }
)

#######################################################################################
#### Data Preprocessing

#' Read 10X alignment data (including V3)
#'
#' This function generates a sparse matrix (genes x cells) from the data generated by 10X's
#' cellranger count pipeline. It can process V2 and V3 data together, producing either a single
#' merged matrix or list of matrices. Also handles multiple data types produced by 10X V3 (Gene
#' Expression, Antibody Capture, CRISPR, CUSTOM).
#'
#' @param sample.dirs List of directories containing either matrix.mtx(.gz) file along with genes.tsv,
#'   (features.tsv), and barcodes.tsv, or outer level 10X output directory (containing outs directory).
#' @param sample.names Vector of names to use for samples (corresponding to sample.dirs)
#' @param merge Whether to merge all matrices of the same data type across samples or leave as list
#'   of matrices (default TRUE).
#' @param num.cells Optional limit on number of cells returned for each sample (only for Gene
#'   Expression data). Retains the cells with the highest numbers of transcripts (default NULL).
#' @param min.umis Minimum UMI threshold for cells (default 0).
#' @param use.filtered Whether to use 10X's filtered data (as opposed to raw). Only relevant for
#'   sample.dirs containing 10X outs directory (default FALSE).
#' @param reference For 10X V<3, specify which reference directory to use if sample.dir is outer
#'   level 10X directory (only necessary if more than one reference used for sequencing).
#'   (default NULL)
#' @return List of merged matrices across data types (returns sparse matrix if only one data type
#'   detected), or nested list of matrices organized by sample if merge=F.
#' @export
#' @examples
#' \dontrun{
#' # 10X output directory V2 -- contains outs/raw_gene_bc_matrices/<reference>/...
#' sample.dir1 <- "path/to/outer/dir1"
#' # 10X output directory V3 -- for two data types, Gene Expression and CUSTOM
#' sample.dir2 <- "path/to/outer/dir2"
#' dges1 <- read10X(list(sample.dir1, sample.dir2), c("sample1", "sample2"), min.umis = 50)
#' ligerex <- createLiger(expr = dges1[["Gene Expression"]], custom = dges1[["CUSTOM"]])
#' }

read10X <- function(sample.dirs, sample.names, merge = T, num.cells = NULL, min.umis = 0,
                    use.filtered = F, reference = NULL) {
  datalist <- list()
  datatypes <- c("Gene Expression")

  if (length(num.cells) == 1) {
    num.cells <- rep(num.cells, length(sample.dirs))
  }
  for (i in seq_along(sample.dirs)) {
    print(paste0("Processing sample ", sample.names[i]))
    sample.dir <- sample.dirs[[i]]
    inner1 <- paste0(sample.dir, "/outs")
    if (dir.exists(inner1)) {
      sample.dir <- inner1
      is_v3 <- dir.exists(paste0(sample.dir, "/filtered_feature_bc_matrix"))
      matrix.prefix <- ifelse(use.filtered, "filtered", "raw")
      if (is_v3) {
        sample.dir <- paste0(sample.dir, "/", matrix.prefix, "_feature_bc_matrix")
      } else {
        if (is.null(reference)) {
          references <- list.dirs(paste0(sample.dir, "/raw_gene_bc_matrices"),
                                  full.names = F,
                                  recursive = F
          )
          if (length(references) > 1) {
            stop("Multiple reference genomes found. Please specify a single one.")
          } else {
            reference <- references[1]
          }
        }
        sample.dir <- paste0(sample.dir, "/", matrix.prefix, "_gene_bc_matrices/", reference)
      }
    } else {
      is_v3 <- file.exists(paste0(sample.dir, "/features.tsv.gz"))
    }
    suffix <- ifelse(is_v3, ".gz", "")
    features.file <- ifelse(is_v3, paste0(sample.dir, "/features.tsv.gz"),
                            paste0(sample.dir, "/genes.tsv")
    )
    matrix.file <- paste0(sample.dir, "/matrix.mtx", suffix)
    barcodes.file <- paste0(sample.dir, "/barcodes.tsv", suffix)

    rawdata <- readMM(matrix.file)
    # convert to dgc matrix
    if (class(rawdata)[1] == "dgTMatrix") {
      rawdata <- as(rawdata, "CsparseMatrix")
    }

    # filter for UMIs first to increase speed
    umi.pass <- which(colSums(rawdata) > min.umis)
    if (length(umi.pass) == 0) {
      print("No cells pass UMI cutoff. Please lower it.")
    }
    rawdata <- rawdata[, umi.pass, drop = F]

    barcodes <- readLines(barcodes.file)[umi.pass]
    # Remove -1 tag from barcodes
    if (all(grepl(barcodes, pattern = "\\-1$"))) {
      barcodes <- as.vector(sapply(barcodes, function(x) {
        strsplit(x, "-")[[1]][1]
      }))
    }

    features <- read.delim(features.file, header = F, stringsAsFactors = F)
    # since some genes are only differentiated by ENSMBL
    rownames(rawdata) <- make.unique(features[, 2])
    colnames(rawdata) <- barcodes

    # split based on 10X datatype -- V3 has Gene Expression, Antibody Capture, CRISPR, CUSTOM
    # V2 has only Gene Expression by default and just two columns
    if (ncol(features) < 3) {
      samplelist <- list(rawdata)
      names(samplelist) <- c("Gene Expression")
    } else {
      sam.datatypes <- features[, 3]
      sam.datatypes.unique <- unique(sam.datatypes)
      # keep track of all unique datatypes
      datatypes <- union(datatypes, unique(sam.datatypes))
      samplelist <- lapply(sam.datatypes.unique, function(x) {
        rawdata[which(sam.datatypes == x), ]
      })
      names(samplelist) <- sam.datatypes.unique
    }

    # num.cells filter only for gene expression data
    if (!is.null(num.cells)) {
      cs <- colSums(samplelist[["Gene Expression"]])
      limit <- ncol(samplelist[["Gene Expression"]])
      if (num.cells[i] > limit) {
        print(paste0(
          "You selected more cells than are in matrix ", i,
          ". Returning all ", limit, " cells."
        ))
        num.cells[i] <- limit
      }
      samplelist[["Gene Expression"]] <- samplelist[["Gene Expression"]][, order(cs, decreasing = T)
                                                                         [1:num.cells[i]]]
    }

    datalist[[i]] <- samplelist
  }
  if (merge) {
    print('Merging samples')
    return_dges <- lapply(datatypes, function(x) {
      mergelist <- lapply(datalist, function(d) {
        d[[x]]
      })
      mergelist <- mergelist[!sapply(mergelist, is.null)]
      sample.names.x <- sample.names[!sapply(mergelist, is.null)]
      MergeSparseDataAll(mergelist, sample.names)
    })
    names(return_dges) <- datatypes

    # if only one type of data present
    if (length(return_dges) == 1) {
      print(paste0("Returning ", datatypes, " data matrix"))
      return(return_dges[[1]])
    }
    return(return_dges)
  } else {
    names(datalist) <- sample.names
    return(datalist)
  }
}

#' Create a liger object.
#'
#' This function initializes a liger object with the raw data passed in. It requires a list of
#' expression (or another single-cell modality) matrices (gene by cell) for at least two datasets.
#' By default, it converts all passed data into sparse matrices (dgCMatrix) to reduce object size.
#' It initializes cell.data with nUMI and nGene calculated for every cell.
#'
#' @param raw.data List of expression matrices (gene by cell). Should be named by dataset.
#' @param make.sparse Whether to convert raw data into sparse matrices (default TRUE).
#' @param take.gene.union Whether to fill out raw.data matrices with union of genes across all
#'   datasets (filling in 0 for missing data) (requires make.sparse=T) (default FALSE).
#' @param remove.missing Whether to remove cells not expressing any measured genes, and genes not
#'   expressed in any cells (if take.gene.union = T, removes only genes not expressed in any
#'   dataset) (default TRUE).
#'
#' @return \code{liger} object with raw.data slot set.
#' @export
#' @examples
#' \dontrun{
#' Y <- matrix(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), nrow = 4, byrow = T)
#' Z <- matrix(c(1, 2, 3, 4, 5, 6, 7, 6, 5, 4, 3, 2), nrow = 4, byrow = T)
#' ligerex <- createLiger(list(y_set = Y, z_set = Z))
#' }

createLiger <- function(raw.data, make.sparse = T, take.gene.union = F,
                        remove.missing = T) {
  if (make.sparse) {
    raw.data <- lapply(raw.data, function(x) {
      if (class(x)[1] == "dgTMatrix" | class(x)[1] == 'dgCMatrix') {
        mat <- as(x, 'CsparseMatrix')
        # Check if dimnames exist
        if (is.null(x@Dimnames[[1]])) {
          stop('Raw data must have both row (gene) and column (cell) names.')
        }
        mat@Dimnames <- x@Dimnames
        return(mat)
      } else {
        as(as.matrix(x), 'CsparseMatrix')
      }
    })
  }
  if (length(Reduce(intersect, lapply(raw.data, colnames))) > 0) {
    stop('At least one cell name is repeated across datasets; please make sure all cell names
         are unique.')
  }
  if (take.gene.union) {
    merged.data <- MergeSparseDataAll(raw.data)
    if (remove.missing) {
      missing_genes <- which(rowSums(merged.data) == 0)
      if (length(missing_genes) > 0) {
        print(
          paste0("Removing ", length(missing_genes),
                 " genes not expressed in any cells across merged datasets.")
        )
        if (length(missing_genes) < 25) {
          print(rownames(merged.data)[missing_genes])
        }
        merged.data <- merged.data[-missing_genes, ]
      }
    }
    raw.data <- lapply(raw.data, function(x) {
      merged.data[, colnames(x)]
    })
  }
  object <- methods::new(
    Class = "liger",
    raw.data = raw.data,
    version = packageVersion("liger")
  )
  # remove missing cells
  if (remove.missing) {
    object <- removeMissingObs(object, use.cols = T)
    # remove missing genes if not already merged
    if (!take.gene.union) {
      object <- removeMissingObs(object, use.cols = F)
    }
  }

  # Initialize cell.data for object with nUMI, nGene, and dataset
  nUMI <- unlist(lapply(object@raw.data, function(x) {
    colSums(x)
  }), use.names = F)
  nGene <- unlist(lapply(object@raw.data, function(x) {
    colSums(x > 0)
  }), use.names = F)
  dataset <- unlist(lapply(seq_along(object@raw.data), function(i) {
    rep(names(object@raw.data)[i], ncol(object@raw.data[[i]]))
  }), use.names = F)
  object@cell.data <- data.frame(nUMI, nGene, dataset)
  rownames(object@cell.data) <- unlist(lapply(object@raw.data, function(x) {
    colnames(x)
  }), use.names = F)

  return(object)
}

#' Normalize raw datasets to column sums
#'
#' This function normalizes data to account for total gene expression across a cell.
#'
#' @param object \code{liger} object.
#'
#' @return \code{liger} object with norm.data slot set.
#' @export
#' @examples
#' \dontrun{
#' Y <- matrix(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), nrow = 4, byrow = T)
#' Z <- matrix(c(1, 2, 3, 4, 5, 6, 7, 6, 5, 4, 3, 2), nrow = 4, byrow = T)
#' ligerex <- createLiger(list(y_set = Y, z_set = Z))
#' ligerex <- normalize(ligerex)
#' }

normalize <- function(object) {
  object <- removeMissingObs(object, slot.use = "raw.data", use.cols = T)
  if (class(object@raw.data[[1]])[1] == "dgTMatrix" |
      class(object@raw.data[[1]])[1] == "dgCMatrix") {
    object@norm.data <- lapply(object@raw.data, Matrix.column_norm)
  } else {
    object@norm.data <- lapply(object@raw.data, function(x) {
      sweep(x, 2, colSums(x), "/")
    })
  }
  return(object)
}

#' Select a subset of informative genes
#'
#' This function identifies highly variable genes from each dataset and combines these gene sets
#' (either by union or intersection) for use in downstream analysis. Assuming that gene
#' expression approximately follows a Poisson distribution, this function identifies genes with
#' gene expression variance above a given variance threshold (relative to mean gene expression).
#' It also provides a log plot of gene variance vs gene expression (with a line indicating expected
#' expression across genes and cells). Selected genes are plotted in green.
#'
#' @param object \code{liger} object. Should have already called normalize.
#' @param alpha.thresh Alpha threshold. Controls upper bound for expected mean gene expression
#'   (lower threshold -> higher upper bound). (default 0.99)
#' @param var.thresh Variance threshold. Main threshold used to identify variable genes. Genes with
#'   expression variance greater than threshold (relative to mean) are selected.
#'   (higher threshold -> fewer selected genes). Accepts single value or vector with separate
#'   var.thresh for each dataset. (default 0.1)
#' @param combine How to combine variable genes across experiments. Either "union" or "intersect".
#'   (default "union")
#' @param keep.unique Keep genes that occur (i.e., there is a corresponding column in raw.data) only
#'    in one dataset (default FALSE)
#' @param capitalize Capitalize gene names to match homologous genes (ie. across species)
#'   (default FALSE)
#' @param do.plot Display log plot of gene variance vs. gene expression for each dataset.
#'   Selected genes are plotted in green. (default TRUE)
#' @param cex.use Point size for plot.

#' @return \code{liger} object with var.genes slot set.
#' @export
#' @examples
#' \dontrun{
#' Y <- matrix(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), nrow = 4, byrow = T)
#' Z <- matrix(c(1, 2, 3, 4, 5, 6, 7, 6, 5, 4, 3, 2), nrow = 4, byrow = T)
#' ligerex <- createLiger(list(y_set = Y, z_set = Z))
#' ligerex <- normalize(ligerex)
#' # use default selectGenes settings
#' ligerex <- selectGenes(ligerex)
#' # select a smaller subset of genes
#' ligerex <- selectGenes(ligerex, var.thresh=0.8)
#' }

selectGenes <- function(object, alpha.thresh = 0.99, var.thresh = 0.1, combine = "union",
                        keep.unique = F, capitalize = F, do.plot = T, cex.use = 0.3) {
  # Expand if only single var.thresh passed
  if (length(var.thresh) == 1) {
    var.thresh <- rep(var.thresh, length(object@raw.data))
  }
  genes.use <- c()
  for (i in 1:length(object@raw.data)) {
    if (capitalize) {
      rownames(object@raw.data[[i]]) <- toupper(rownames(object@raw.data[[i]]))
      rownames(object@norm.data[[i]]) <- toupper(rownames(object@norm.data[[i]]))
    }
    trx_per_cell <- colSums(object@raw.data[[i]])
    # Each gene's mean expression level (across all cells)
    gene_expr_mean <- rowMeansFast(object@norm.data[[i]])
    # Each gene's expression variance (across all cells)
    gene_expr_var <- rowVarsFast(object@norm.data[[i]], gene_expr_mean)
    names(gene_expr_mean) <- names(gene_expr_var) <- rownames(object@norm.data[[i]])
    nolan_constant <- mean((1 / trx_per_cell))
    alphathresh.corrected <- alpha.thresh / nrow(object@raw.data[[i]])
    genemeanupper <- gene_expr_mean + qnorm(1 - alphathresh.corrected / 2) *
                     sqrt(gene_expr_mean * nolan_constant / ncol(object@raw.data[[i]]))
    genes.new <- names(gene_expr_var)[which(gene_expr_var / nolan_constant > genemeanupper &
                                            log10(gene_expr_var) > log10(gene_expr_mean) +
                                              (log10(nolan_constant) + var.thresh[i]))]
    if (do.plot) {
      plot(log10(gene_expr_mean), log10(gene_expr_var), cex = cex.use,
           xlab='Gene Expression Mean (log10)',
           ylab='Gene Expression Variance (log10)')

      points(log10(gene_expr_mean[genes.new]), log10(gene_expr_var[genes.new]),
             cex = cex.use, col = "green")
      abline(log10(nolan_constant), 1, col = "purple")

      legend("bottomright", paste0("Selected genes: ", length(genes.new)), pch = 20, col = "green")
      title(main = names(object@raw.data)[i])
    }
    if (combine == "union") {
      genes.use <- union(genes.use, genes.new)
    }
    if (combine == "intersection") {
      if (length(genes.use) == 0) {
        genes.use <- genes.new
      }
      genes.use <- intersect(genes.use, genes.new)
    }
  }
  if (!keep.unique) {
    for (i in 1:length(object@raw.data)) {
      genes.use <- genes.use[genes.use %in% rownames(object@raw.data[[i]])]
    }
  }
  if (length(genes.use) == 0) {
    warning("No genes were selected; lower var.thresh values or choose 'union' for combine parameter",
            immediate. = T)
  }
  object@var.genes <- genes.use
  return(object)
}

#' Scale genes by root-mean-square across cells
#'
#' This function scales normalized gene expression data after variable genes have been selected.
#' Note that the data is not mean-centered before scaling because expression values must remain
#' positive (NMF only accepts positive values). It also removes cells which do not have any
#' expression across the genes selected, by default.
#'
#' @param object \code{liger} object. Should call normalize and selectGenes before calling.
#' @param remove.missing Whether to remove cells from scale.data with no gene expression
#'   (default TRUE).
#'
#' @return \code{liger} object with scale.data slot set.
#' @export
#' @examples
#' \dontrun{
#' Y <- matrix(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), nrow = 4, byrow = T)
#' Z <- matrix(c(1, 2, 3, 4, 5, 6, 7, 6, 5, 4, 3, 2), nrow = 4, byrow = T)
#' ligerex <- createLiger(list(y_set = Y, z_set = Z))
#' ligerex <- normalize(ligerex)
#' # select genes
#' ligerex <- selectGenes(ligerex)
#' ligerex <- scaleNotCenter(ligerex)
#' }

scaleNotCenter <- function(object, remove.missing = T) {
  if (class(object@raw.data[[1]])[1] == "dgTMatrix" |
      class(object@raw.data[[1]])[1] == "dgCMatrix") {
    object@scale.data <- lapply(1:length(object@norm.data), function(i) {
      scaleNotCenterFast(t(object@norm.data[[i]][object@var.genes, ]))
    })
    # TODO: Preserve sparseness later on (convert inside optimizeALS)
    object@scale.data <- lapply(object@scale.data, function(x) {
      as.matrix(x)
    })
  } else {
    object@scale.data <- lapply(1:length(object@norm.data), function(i) {
      scale(t(object@norm.data[[i]][object@var.genes, ]), center = F, scale = T)
    })
  }
  names(object@scale.data) <- names(object@norm.data)
  for (i in 1:length(object@scale.data)) {
    object@scale.data[[i]][is.na(object@scale.data[[i]])] <- 0
    rownames(object@scale.data[[i]]) <- colnames(object@raw.data[[i]])
    colnames(object@scale.data[[i]]) <- object@var.genes
  }
  # may want to remove such cells before scaling -- should not matter for large datasets?
  if (remove.missing) {
    object <- removeMissingObs(object, slot.use = "scale.data", use.cols = F)
  }
  return(object)
}

#' Remove cells/genes with no expression across any genes/cells
#'
#' Removes cells/genes from chosen slot with no expression in any genes or cells respectively.
#'
#' @param object \code{liger} object (scale.data or norm.data must be set).
#' @param slot.use The data slot to filter (takes "raw.data" and "scale.data") (default "raw.data").
#' @param use.cols Treat each column as a cell (default TRUE).
#'
#' @return \code{liger} object with modified raw.data (or chosen slot) (dataset names preserved).
#' @export
#' @examples
#' \dontrun{
#' # liger object
#' ligerex
#' ligerex <- removeMissingObs(ligerex)
#' }

removeMissingObs <- function(object, slot.use = "raw.data", use.cols = T) {
  filter.data <- slot(object, slot.use)
  removed <- ifelse((slot.use %in% c("raw.data", "norm.data")) & (use.cols == T),
                    yes = "cells", no = "genes")
  expressed <- ifelse(removed == "cells", yes = " any genes", no = "")
  filter.data <- lapply(seq_along(filter.data), function(x) {
    if (use.cols) {
      missing <- which(colSums(filter.data[[x]]) == 0)
    } else {
      missing <- which(rowSums(filter.data[[x]]) == 0)
    }
    if (length(missing) > 0) {
      print(paste0(
        "Removing ",  length(missing), " ", removed, " not expressing", expressed, " in ",
        names(object@raw.data)[x], "."
      ))
      if (use.cols) {
        if (length(missing) < 25) {
          print(colnames(filter.data[[x]])[missing])
        }
        subset <- filter.data[[x]][, -missing]
      } else {
        if (length(missing) < 25) {
          print(rownames(filter.data[[x]])[missing])
        }
        subset <- filter.data[[x]][-missing, ]
      }
    } else {
      subset <- filter.data[[x]]
    }
    subset
  })
  names(filter.data) <- names(object@raw.data)
  slot(object, slot.use) <- filter.data
  return(object)
}

#######################################################################################
#### Factorization

#' Perform iNMF on scaled datasets
#'
#' @description
#' Perform integrative non-negative matrix factorization to return factorized H, W, and V matrices.
#' It optimizes the iNMF objective function using block coordinate descent (alternating non-negative
#' least squares), where the number of factors is set by k. TODO: include objective function
#' equation here in documentation (using deqn)
#'
#' For each dataset, this factorization produces an H matrix (cells by k), a V matrix (k by genes),
#' and a shared W matrix (k by genes). The H matrices represent the cell factor loadings.
#' W is held consistent among all datasets, as it represents the shared components of the metagenes
#' across datasets. The V matrices represent the dataset-specific components of the metagenes.
#'
#' @param object \code{liger} object. Should normalize, select genes, and scale before calling.
#' @param k Inner dimension of factorization (number of factors). Run suggestK to determine
#'   appropriate value; a general rule of thumb is that a higher k will be needed for datasets with
#'   more sub-structure.
#' @param lambda Regularization parameter. Larger values penalize dataset-specific effects more
#'   strongly (ie. alignment should increase as lambda increases). Run suggestLambda to determine
#'   most appropriate value for balancing dataset alignment and agreement (default 5.0).
#' @param thresh Convergence threshold. Convergence occurs when |obj0-obj|/(mean(obj0,obj)) < thresh.
#'   (default 1e-4)
#' @param max.iters Maximum number of block coordinate descent iterations to perform (default 100).
#' @param nrep Number of restarts to perform (iNMF objective function is non-convex, so taking the
#'   best objective from multiple successive initializations is recommended). For easier
#'   reproducibility, this increments the random seed by 1 for each consecutive restart, so future
#'   factorizations of the same dataset can be run with one rep if necessary. (default 1)
#' @param H.init Initial values to use for H matrices. (default NULL)
#' @param W.init Initial values to use for W matrix (default NULL)
#' @param V.init Initial values to use for V matrices (default NULL)
#' @param rand.seed Random seed to allow reproducible results (default 1).
#' @param print.obj Print objective function values after convergence (default FALSE).
#' @param ... Arguments passed to other methods
#'
#' @return \code{liger} object with H, W, and V slots set.
#' @export
#'
#' @examples
#' \dontrun{
#' Y <- matrix(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), nrow = 4, byrow = T)
#' Z <- matrix(c(1, 2, 3, 4, 5, 6, 7, 6, 5, 4, 3, 2), nrow = 4, byrow = T)
#' ligerex <- createLiger(list(y_set = Y, z_set = Z))
#' ligerex <- normalize(ligerex)
#' # select genes
#' ligerex <- selectGenes(ligerex)
#' ligerex <- scaleNotCenter(ligerex)
#' # get factorization using three restarts and 20 factors
#' ligerex <- optimizeALS(ligerex, k = 20, lambda = 5, nrep = 3)
#' }
#'
optimizeALS <- function(
  object,
  ...
) {
  UseMethod(generic = 'optimizeALS', object = object)
}

#' @rdname optimizeALS
#' @export
#' @method optimizeALS list
#'
optimizeALS.list  <- function(
  object,
  k,
  lambda = 5.0,
  thresh = 1e-4,
  max.iters = 100,
  nrep = 1,
  H.init = NULL,
  W.init = NULL,
  V.init = NULL,
  rand.seed = 1,
  print.obj = FALSE,
  ...
) {
  if (!all(sapply(X = object, FUN = is.matrix))) {
    stop("All values in 'object' must be a matrix")
  }
  E <- object
  N <- length(x = E)
  ns <- sapply(X = E, FUN = nrow)
  if (k >= min(ns)) {
    stop('Select k lower than the number of cells in smallest dataset: ', min(ns))
  }
  tmp <- gc()
  g <- ncol(x = E[[1]])
  if (k >= g) {
    stop('Select k lower than the number of variable genes: ', g)
  }
  W_m <- matrix(data = 0, nrow = k, ncol = g)
  V_m <- lapply(
    X = 1:N,
    FUN = function(i) {
      return(matrix(data = 0, nrow = k, ncol = g))
    }
  )
  H_m <- lapply(
    X = ns,
    FUN = function(n) {
      return(matrix(data = 0, nrow = n, ncol = k))
    }
  )
  tmp <- gc()
  best_obj <- Inf
  run_stats <- matrix(data = 0, nrow = nrep, ncol = 2)
  for (i in 1:nrep) {
    set.seed(seed = rand.seed + i - 1)
    start_time <- Sys.time()
    W <- matrix(
      data = abs(x = runif(n = g * k, min = 0, max = 2)),
      nrow = k,
      ncol = g
    )
    V <- lapply(
      X = 1:N,
      FUN = function(i) {
        return(matrix(
          data = abs(x = runif(n = g * k, min = 0, max = 2)),
          nrow = k,
          ncol = g
        ))
      }
    )
    H <- lapply(
      X = ns,
      FUN = function(n) {
        return(matrix(
          data = abs(x = runif(n = n * k, min = 0, max = 2)),
          nrow = n,
          ncol = k
        ))
      }
    )
    tmp <- gc()
    if (!is.null(x = W.init)) {
      W <- W.init
    }
    if (!is.null(x = V.init)) {
      V <- V.init
    }
    if (!is.null(x = H.init)) {
      H <- H.init
    }
    delta <- 1
    iters <- 0
    pb <- txtProgressBar(min = 0, max = max.iters, style = 3)
    sqrt_lambda <- sqrt(x = lambda)
    obj0 <- sum(sapply(
      X = 1:N,
      FUN = function(i) {
        return(norm(x = E[[i]] - H[[i]] %*% (W + V[[i]]), type = "F") ^ 2)
      }
    )) +
      sum(sapply(
        X = 1:N,
        FUN = function(i) {
          return(lambda * norm(x = H[[i]] %*% V[[i]], type = "F") ^ 2)
        }
      ))
    tmp <- gc()
    while (delta > thresh & iters < max.iters) {
      H <- lapply(
        X = 1:N,
        FUN = function(i) {
          return(t(x = solveNNLS(
            C = rbind(t(x = W) + t(x = V[[i]]), sqrt_lambda * t(x = V[[i]])),
            B = rbind(t(x = E[[i]]), matrix(data = 0, nrow = g, ncol = ns[i]))
          )))
        }
      )
      tmp <- gc()
      V <- lapply(
        X = 1:N,
        FUN = function(i) {
          return(solveNNLS(
            C = rbind(H[[i]], sqrt_lambda * H[[i]]),
            B = rbind(E[[i]] - H[[i]] %*% W, matrix(data = 0, nrow = ns[[i]], ncol = g))
          ))
        }
      )
      tmp <- gc()
      W <- solveNNLS(
        C = rbindlist(mat_list = H),
        B = rbindlist(mat_list = lapply(
          X = 1:N,
          FUN = function(i) {
            return(E[[i]] - H[[i]] %*% V[[i]])
          }
        ))
      )
      tmp <- gc()
      obj <- sum(sapply(
        X = 1:N,
        FUN = function(i) {
          return(norm(x = E[[i]] - H[[i]] %*% (W + V[[i]]), type = "F") ^ 2)
        }
      )) +
        sum(sapply(
          X = 1:N,
          FUN = function(i) {
            return(lambda * norm(x = H[[i]] %*% V[[i]], type = "F") ^ 2)
          }
        ))
      tmp <- gc()
      delta <- abs(x = obj0 - obj) / (mean(obj0, obj))
      obj0 <- obj
      iters <- iters + 1
      setTxtProgressBar(pb = pb, value = iters)
    }
    setTxtProgressBar(pb = pb, value = max.iters)
    if (iters == max.iters) {
      print("Warning: failed to converge within the allowed number of iterations.
            Re-running with a higher max.iters is recommended.")
    }
    if (obj < best_obj) {
      W_m <- W
      H_m <- H
      V_m <- V
      best_obj <- obj
      best_seed <- rand.seed + i - 1
    }
    end_time <- difftime(time1 = Sys.time(), time2 = start_time, units = "auto")
    run_stats[i, 1] <- as.double(x = end_time)
    run_stats[i, 2] <- iters
    cat(
      "\nConverged in ",
      run_stats[i, 1],
      " ",
      units(x = end_time),
      ", ",
      iters,
      " iterations.\n",
      sep = ""
    )
    if (print.obj) {
      cat("Objective:", obj, "\n")
    }
  }
  cat("Best results with seed ", best_seed, ".\n", sep = "")
  out <- list()
  out$H <- H_m
  for (i in 1:length(x = object)) {
    rownames(x = out$H[[i]]) <- rownames(x = object[[i]])
  }
  out$V <- V_m
  names(x = out$V) <- names(x = out$H) <- names(x = object)
  out$W <- W_m
  return(out)
}

#' @importFrom methods slot<-
#'
#' @rdname optimizeALS
#' @export
#' @method optimizeALS liger
#'
optimizeALS.liger <- function(
  object,
  k,
  lambda = 5.0,
  thresh = 1e-4,
  max.iters = 100,
  nrep = 1,
  H.init = NULL,
  W.init = NULL,
  V.init = NULL,
  rand.seed = 1,
  print.obj = FALSE,
  ...
) {
  object <- removeMissingObs(
    object = object,
    slot.use = 'scale.data',
    use.cols = FALSE
  )
  out <- optimizeALS(
    object = object@scale.data,
    k = k,
    lambda = lambda,
    thresh = thresh,
    max.iters = max.iters,
    nrep = nrep,
    H.init = H.init,
    W.init = W.init,
    V.init = V.init,
    rand.seed = rand.seed,
    print.obj = print.obj
  )
  names(x = out$H) <- names(x = out$V) <- names(x = object@raw.data)
  for (i in 1:length(x = object@scale.data)) {
    rownames(x = out$H[[i]]) <- rownames(x = object@scale.data[[i]])
  }
  colnames(x = out$W) <- object@var.genes
  for (i in names(x = out)) {
    slot(object = object, name = i) <- out[[i]]
  }
  object@parameters$lambda <- lambda
  return(object)
}

#' Perform factorization for new value of k
#'
#' This uses an efficient strategy for updating that takes advantage of the information in the
#' existing factorization. It is most recommended for values of k smaller than current value,
#' where it is more likely to speed up the factorization.
#'
#' @param object \code{liger} object. Should call optimizeALS before calling.
#' @param k.new Inner dimension of factorization (number of factors)
#' @param lambda Regularization parameter. By default, this will use the lambda last used with
#'   optimizeALS.
#' @param thresh Convergence threshold. Convergence occurs when |obj0-obj|/(mean(obj0,obj)) < thresh
#'   (default 1e-4).
#' @param max.iters Maximum number of block coordinate descent iterations to perform (default 100).
#' @param rand.seed Random seed to set. Only relevant if k.new > k. (default 1)
#'
#' @return \code{liger} object with H, W, and V slots reset.
#' @export
#' @importFrom plyr rbind.fill.matrix
#' @examples
#' \dontrun{
#' Y <- matrix(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), nrow = 4, byrow = T)
#' Z <- matrix(c(1, 2, 3, 4, 5, 6, 7, 6, 5, 4, 3, 2), nrow = 4, byrow = T)
#' ligerex <- createLiger(list(y_set = Y, z_set = Z))
#' ligerex <- normalize(ligerex)
#' ligerex <- selectGenes(ligerex)
#' ligerex <- scaleNotCenter(ligerex)
#' # get factorization using three restarts and 20 factors
#' ligerex <- optimizeALS(ligerex, k = 20, lambda = 5, nrep = 3)
#' # decide to run with k = 15 instead (keeping old lambda the same)
#' ligerex <- optimizeNewK(ligerex, k.new = 15)
#' }

optimizeNewK <- function(object, k.new, lambda = NULL, thresh = 1e-4, max.iters = 100,
                         rand.seed = 1) {
  if (is.null(lambda)) {
    lambda <- object@parameters$lambda
  }
  k <- ncol(object@H[[1]])
  if (k.new == k) {
    return(object)
  }
  H <- object@H
  W <- object@W
  V <- object@V

  if (k.new > k) {
    set.seed(rand.seed)
    sqrt_lambda <- sqrt(lambda)
    g <- ncol(W)
    N <- length(H)
    ns <- sapply(H, nrow)
    W_new <- matrix(abs(runif(g * k, 0, 2)), k.new - k, g)
    V_new <- lapply(1:N, function(i) {
      matrix(abs(runif(g * (k.new - k), 0, 2)), k.new - k, g)
    })
    H_new <- lapply(ns, function(n) {
      matrix(abs(runif(n * (k.new - k), 0, 2)), n, k.new - k)
    })
    H_new <- lapply(1:N, function(i) {
      t(solveNNLS(
        rbind(t(W_new) + t(V_new[[i]]), sqrt_lambda * t(V_new[[i]])),
        rbind(
          t(object@scale.data[[i]] - H[[i]] %*% (W + V[[i]])),
          matrix(0, nrow = g, ncol = ns[i])
        )
      ))
    })
    V_new <- lapply(1:N, function(i) {
      solveNNLS(
        rbind(H_new[[i]], sqrt_lambda * H_new[[i]]),
        rbind(
          object@scale.data[[i]] - H[[i]] %*% (W + V[[i]]) - H_new[[i]] %*% W_new,
          matrix(0, nrow = ns[[i]], ncol = g)
        )
      )
    })
    W_new <- solveNNLS(
      rbind.fill.matrix(H_new),
      rbind.fill.matrix(lapply(1:N, function(i) {
        object@scale.data[[i]] - H[[i]] %*% (W + V[[i]]) - H_new[[i]] %*% V_new[[i]]
      }))
    )
    H <- lapply(1:N, function(i) {
      cbind(H[[i]], H_new[[i]])
    })
    V <- lapply(1:N, function(i) {
      rbind(V[[i]], V_new[[i]])
    })
    W <- rbind(W, W_new)
  }
  else {
    deltas <- rep(0, k)
    for (i in 1:length(object@H))
    {
      deltas <- deltas + sapply(1:k, function(x) {
        norm(H[[i]][, k] %*% t(W[k, ] + V[[i]][k, ]), "F")
      })
    }
    k.use <- order(deltas, decreasing = T)[1:k.new]
    W <- W[k.use, ]
    H <- lapply(H, function(x) {
      x[, k.use]
    })
    V <- lapply(V, function(x) {
      x[k.use, ]
    })
  }
  object <- optimizeALS(object, k.new,
                        lambda = lambda, thresh = thresh, max.iters = max.iters,
                        H.init = H, W.init = W, V.init = V, rand.seed = rand.seed)
  return(object)
}

#' Perform factorization for new data
#'
#' Uses an efficient strategy for updating that takes advantage of the information in the existing
#' factorization. Assumes that selected genes (var.genes) are represented in the new datasets.
#'
#' @param object \code{liger} object. Should call optimizeALS before calling.
#' @param new.data List of raw data matrices (one or more). Each list entry should be named.
#' @param which.datasets List of datasets to append new.data to if add.to.existing is true.
#'   Otherwise, the most similar existing datasets for each entry in new.data.
#' @param add.to.existing Add the new data to existing datasets or treat as totally new datasets
#'   (calculate new Vs?) (default TRUE)
#' @param lambda Regularization parameter. By default, this will use the lambda last used with
#'   optimizeALS.
#' @param thresh Convergence threshold. Convergence occurs when |obj0-obj|/(mean(obj0,obj)) < thresh
#'   (default 1e-4).
#' @param max.iters Maximum number of block coordinate descent iterations to perform (default 100).
#'
#' @return \code{liger} object with H, W, and V slots reset. Raw.data, norm.data, and scale.data will
#'   also be updated to include the new data.
#' @export
#' @examples
#' \dontrun{
#' Y <- matrix(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), nrow = 4, byrow = T)
#' Z <- matrix(c(1, 2, 3, 4, 5, 6, 7, 6, 5, 4, 3, 2), nrow = 4, byrow = T)
#' ligerex <- createLiger(list(y_set = Y, z_set = Z))
#' ligerex <- normalize(ligerex)
#' ligerex <- selectGenes(ligerex)
#' ligerex <- scaleNotCenter(ligerex)
#' # get factorization using three restarts and 20 factors
#' ligerex <- optimizeALS(ligerex, k = 20, lambda = 5, nrep = 3)
#' # acquire new data from the same cell type, let's add it to existing datasets
#' Y_new <- matrix(41:52, nrow = 4, byrow = T)
#' Z_new <- matrix(c(51:57, 56:52), nrow = 4, byrow = T)
#' new_data <- list(Y_set = Y_new, Z_set = Z_new)
#' ligerex2 <- optimizeNewData(ligerex, new.data = new_data, which.datasets = list('y_set', 'z_set'))
#' # acquire new data from different cell type, we'll just add another dataset
#' X <- matrix(35:46, nrow = 4, byrow = T)
#' # it's probably most similar to y_set
#' ligerex <- optimizeNewData(ligerex, new.data = list(x_set = X), which.datasets = list('y_set),
#'                            add.to.existing = F)
#' }

optimizeNewData <- function(object, new.data, which.datasets, add.to.existing = T, lambda = NULL,
                            thresh = 1e-4, max.iters = 100) {
  if (is.null(lambda)) {
    lambda <- object@parameters$lambda
  }
  if (add.to.existing) {
    for (i in 1:length(new.data)) {
      print(dim(object@raw.data[[which.datasets[[i]]]]))
      object@raw.data[[which.datasets[[i]]]] <- cbind(
        object@raw.data[[which.datasets[[i]]]],
        new.data[[i]]
      )
      print(dim(object@raw.data[[which.datasets[[i]]]]))
    }
    object <- normalize(object)
    object <- scaleNotCenter(object)
    sqrt_lambda <- sqrt(lambda)
    g <- ncol(object@W)
    H_new <- lapply(1:length(new.data), function(i) {
      t(solveNNLS(
        rbind(
          t(object@W) + t(object@V[[which.datasets[[i]]]]),
          sqrt_lambda * t(object@V[[which.datasets[[i]]]])
        ),
        rbind(
          t(object@scale.data[[which.datasets[[i]]]][colnames(new.data[[i]]), ]),
          matrix(0, nrow = g, ncol = ncol(new.data[[i]]))
        )
      ))
    })
    for (i in 1:length(new.data)) {
      object@H[[which.datasets[[i]]]] <- rbind(object@H[[which.datasets[[i]]]], H_new[[i]])
    }
  } else {
    old.names <- names(object@raw.data)
    new.names <- names(new.data)
    combined.names <- c(old.names, new.names)
    for (i in 1:length(which.datasets)) {
      object@V[[names(new.data)[i]]] <- object@V[[which.datasets[[i]]]]
    }
    object@raw.data <- c(object@raw.data, new.data)
    names(object@raw.data) <- names(object@V) <- combined.names
    object <- normalize(object)
    object <- scaleNotCenter(object)
    ns <- lapply(object@raw.data, ncol)
    N <- length(ns)
    g <- ncol(object@W)
    sqrt_lambda <- sqrt(lambda)
    for (i in 1:N) {
      print(ns[[i]])
      print(dim(object@raw.data[[i]]))
      print(dim(object@norm.data[[i]]))
      print(dim(object@scale.data[[i]]))
      print(dim(object@V[[i]]))
    }
    H_new <- lapply(1:length(new.data), function(i) {
      t(solveNNLS(rbind(t(object@W) + t(object@V[[new.names[i]]]),
                         sqrt_lambda * t(object@V[[new.names[i]]])),
                   rbind(t(object@scale.data[[new.names[i]]]),
                         matrix(0, nrow = g, ncol = ncol(new.data[[i]])))
      )
      )
    })
    object@H <- c(object@H, H_new)
    names(object@H) <- combined.names
  }
  k <- ncol(object@H[[1]])
  object <- optimizeALS(object, k, lambda, thresh, max.iters,
                        H.init = object@H, W.init = object@W,
                        V.init = object@V)
  return(object)
}

#' Perform factorization for subset of data
#'
#' Uses an efficient strategy for updating that takes advantage of the information in the existing
#' factorization. Can use either cell names or cluster names to subset. For more basic subsetting
#' functionality (without automatic optimization), see subsetLiger.
#'
#' @param object \code{liger} object. Should call optimizeALS before calling.
#' @param cell.subset List of cell names to retain from each dataset (same length as number of
#'   datasets).
#' @param cluster.subset Clusters for which to keep cells (ie. c(1, 5, 6)). Should pass in either
#'   cell.subset or cluster.subset but not both.
#' @param lambda Regularization parameter. By default, uses last used lambda.
#' @param thresh Convergence threshold. Convergence occurs when |obj0-obj|/(mean(obj0,obj)) < thresh
#'   (default 1e-4).
#' @param max.iters Maximum number of block coordinate descent iterations to perform (default 100).
#' @param datasets.scale Names of datasets to rescale after subsetting (default NULL).
#'
#' @return \code{liger} object with H, W, and V slots reset. Scale.data
#'   (if desired) will also be updated to reflect the subset.
#' @export
#' @examples
#' \dontrun{
#' Y <- matrix(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), nrow = 4, byrow = T)
#' Z <- matrix(c(1, 2, 3, 4, 5, 6, 7, 6, 5, 4, 3, 2), nrow = 4, byrow = T)
#' colnames(Y) <- c('a', 'b', 'c')
#' colnames(Z) <- c('p', 'q', 'r')
#' ligerex <- createLiger(list(y_set = Y, z_set = Z))
#' ligerex <- normalize(ligerex)
#' ligerex <- selectGenes(ligerex)
#' ligerex <- scaleNotCenter(ligerex)
#' # get factorization using three restarts and 20 factors
#' ligerex <- optimizeALS(ligerex, k = 20, lambda = 5, nrep = 3)
#' # now want to look at only subset of data
#' ligerex2 <- optimizeSubset(ligerex, cell.subset = list(c('a', 'b'), c('q')))
#' }

optimizeSubset <- function(object, cell.subset = NULL, cluster.subset = NULL, lambda = NULL,
                           thresh = 1e-4, max.iters = 100, datasets.scale = NULL) {
  if (is.null(lambda)) {
    lambda <- object@parameters$lambda
  }
  if (is.null(cell.subset) & is.null(cluster.subset)) {
    stop("Please specify a cell subset or cluster subset.")
  }
  else if (is.null(cell.subset) & !is.null(cluster.subset)) {
    cell.subset <- lapply(1:length(object@scale.data), function(i) {
      which(object@clusters[rownames(object@scale.data[[i]])] %in% cluster.subset)
    })
  }
  old_names <- names(object@raw.data)
  H <- object@H
  H <- lapply(1:length(object@H), function(i) {
    object@H[[i]][cell.subset[[i]], ]
  })
  object@raw.data <- lapply(1:length(object@raw.data), function(i) {
    object@raw.data[[i]][, cell.subset[[i]]]
  })
  object@cell.data <- droplevels(object@cell.data[cell.subset, ])
  for (i in 1:length(object@norm.data)) {
    object@norm.data[[i]] <- object@norm.data[[i]][, cell.subset[[i]]]
    if (names(object@norm.data)[i] %in% datasets.scale) {
      object@scale.data[[i]] <- scale(t(object@norm.data[[i]][object@var.genes, ]),
                                      scale = T, center = F)
      object@scale.data[[i]][is.na(object@scale.data[[i]])] <- 0
    } else {
      object@scale.data[[i]] <- t(object@norm.data[[i]][object@var.genes, ])
    }
    print(dim(object@scale.data[[i]]))
  }

  names(object@raw.data) <- names(object@norm.data) <- names(object@H) <- old_names
  k <- ncol(H[[1]])
  object <- optimizeALS(object, k = k, lambda = lambda, thresh = thresh, max.iters = max.iters,
                        H.init = H, W.init = object@W, V.init = object@V)
  return(object)
}

#' Perform factorization for new lambda value
#'
#' Uses an efficient strategy for updating that takes advantage of the information in the existing
#' factorization; uses previous k. Recommended mainly when re-optimizing for higher lambda and when
#' new lambda value is significantly different; otherwise may not return optimal results.
#'
#' @param object \code{liger} object. Should call optimizeALS before calling.
#' @param new.lambda Regularization parameter. Larger values penalize dataset-specific effects more
#' strongly.
#' @param thresh Convergence threshold. Convergence occurs when |obj0-obj|/(mean(obj0,obj)) < thresh
#' @param max.iters Maximum number of block coordinate descent iterations to perform (default 100).
#' @param rand.seed Random seed for reproducibility (default 1).
#'
#' @return \code{liger} object with optimized factorization values
#' @export
#' @examples
#' \dontrun{
#' Y <- matrix(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), nrow = 4, byrow = T)
#' Z <- matrix(c(1, 2, 3, 4, 5, 6, 7, 6, 5, 4, 3, 2), nrow = 4, byrow = T)
#' ligerex <- createLiger(list(y_set = Y, z_set = Z))
#' ligerex <- normalize(ligerex)
#' ligerex <- selectGenes(ligerex)
#' ligerex <- scaleNotCenter(ligerex)
#' # get factorization using three restarts and 20 factors
#' ligerex <- optimizeALS(ligerex, k = 20, lambda = 5, nrep = 3)
#' # decide to run with lambda = 15 instead (keeping k the same)
#' ligerex <- optimizeNewLambda(ligerex, new.lambda = 15)
#' }

optimizeNewLambda <- function(object, new.lambda, thresh = 1e-4, max.iters = 100, rand.seed = 1) {
  k <- ncol(object@H[[1]])
  H <- object@H
  W <- object@W
  if (new.lambda < object@parameters$lambda) {
    print(paste("New lambda less than current lambda; new factorization may not be optimal.",
                "Re-optimization with optimizeAlS recommended instead."))
  }
  object <- optimizeALS(object, k, lambda = new.lambda, thresh = thresh, max.iters = max.iters,
                        H.init = H, W.init = W, rand.seed = rand.seed)
  return(object)
}

#' Visually suggest appropriate lambda value
#'
#' Can be used to select appropriate value of lambda for factorization of particular dataset. Plot
#' alignment and agreement for various test values of lambda. Most appropriate lambda
#' is likely around the "elbow" of the alignment plot (when alignment stops increasing). This will
#' likely also correspond to slower decrease in agreement. Depending on number of cores used,
#' this process can take 10-20 minutes.
#'
#' @param object \code{liger} object. Should normalize, select genes, and scale before calling.
#' @param k Number of factors to use in test factorizations. See optimizeALS documentation.
#' @param lambda.test Vector of lambda values to test. If not given, use default set spanning
#'   0.25 to 60
#' @param rand.seed Random seed for reproducibility (default 1).
#' @param num.cores Number of cores to use for optimizing factorizations in parallel (default 1).
#' @param thresh Convergence threshold. Convergence occurs when |obj0-obj|/(mean(obj0,obj)) < thresh
#' @param max.iters Maximum number of block coordinate descent iterations to perform
#' @param knn_k Number of nearest neighbors for within-dataset knn in quantileAlignSNF (default 20).
#' @param k2 Horizon parameter for quantileAlignSNF (default 500).
#' @param ref_dataset Reference dataset for quantileAlignSNF (defaults to larger dataset).
#' @param resolution Resolution for quantileAlignSNF (default 1).
#' @param gen.new Do not use optimizeNewLambda in factorizations. Recommended to set TRUE
#'   when looking at only a small range of lambdas (ie. 1:7) (default FALSE)
#' @param nrep Number restarts to perform at each lambda value tested (increase to produce
#'   smoother curve if results unclear) (default 1).
#' @param return.data Whether to return list of data matrices (raw) or dataframe (processed)
#'   instead of ggplot object (default FALSE).
#' @param return.raw If return.results TRUE, whether to return raw data (in format described below),
#'   or dataframe used to produce ggplot object. Raw data is matrix of alignment values for each
#'   lambda value tested (each column represents a different rep for nrep).(default FALSE)
#'
#' @return Matrix of results if indicated or ggplot object. Plots alignment vs. lambda to console.
#' @import doSNOW
#' @importFrom foreach foreach
#' @importFrom foreach "%dopar%"
#' @importFrom ggplot2 ggplot aes geom_point geom_line guides guide_legend labs theme theme_classic
#' @export
#' @examples
#' \dontrun{
#' Y <- matrix(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), nrow = 4, byrow = T)
#' Z <- matrix(c(1, 2, 3, 4, 5, 6, 7, 6, 5, 4, 3, 2), nrow = 4, byrow = T)
#' ligerex <- createLiger(list(y_set = Y, z_set = Z))
#' ligerex <- normalize(ligerex)
#' ligerex <- selectGenes(ligerex)
#' ligerex <- scaleNotCenter(ligerex)
#' # examine plot for most appropriate lambda, use multiple cores for faster results
#' suggestLambda(ligerex, k = 20, num.cores = 4)
#' }

suggestLambda <- function(object, k, lambda.test = NULL, rand.seed = 1, num.cores = 1,
                          thresh = 1e-4, max.iters = 100, knn_k = 20, k2 = 500, ref_dataset = NULL,
                          resolution = 1, gen.new = F, nrep = 1, return.data = F, return.raw = F) {
  if (is.null(lambda.test)) {
    lambda.test <- c(seq(0.25, 1, 0.25), seq(2, 10, 1), seq(15, 60, 5))
  }
  time_start <- Sys.time()
  # optimize smallest lambda value first to take advantage of efficient updating
  print("This operation may take several minutes depending on number of values being tested")
  rep_data <- list()
  for (r in 1:nrep) {
    print(paste0("Preprocessing for rep ", r,
                 ": optimizing initial factorization with smallest test lambda=",
                 lambda.test[1]))
    object <- optimizeALS(object, k = k, thresh = thresh, lambda = lambda.test[1],
                          max.iters = max.iters, nrep = 1, rand.seed = (rand.seed + r - 1))
    print('Progress now represents completed factorizations (out of total number of lambda values)')
    cl <- makeCluster(num.cores)
    registerDoSNOW(cl)
    pb <- txtProgressBar(min = 0, max = length(lambda.test), style = 3, initial = 1, file = "")
    # define progress bar function
    progress <- function(n) setTxtProgressBar(pb, n)
    opts <- list(progress = progress)
    data_matrix <- foreach(i = 1:length(lambda.test), .combine = "rbind", .options.snow = opts,
                           .packages = 'liger') %dopar% {
       if (i != 1) {
         if (gen.new) {
           ob.test <- optimizeALS(object,
                                  k = k, lambda = lambda.test[i], thresh = thresh,
                                  max.iters = max.iters, rand.seed = (rand.seed + r - 1)
           )
         } else {
           ob.test <- optimizeNewLambda(object,
                                        new.lambda = lambda.test[i], thresh = thresh,
                                        max.iters = max.iters, rand.seed = (rand.seed + r - 1)
           )
         }
       } else {
         ob.test <- object
       }
       ob.test <- quantileAlignSNF(ob.test, knn_k = knn_k,
                                   k2 = k2, resolution = resolution,
                                   ref_dataset = ref_dataset,
                                   id.number = i
       )
       calcAlignment(ob.test)
    }
    close(pb)
    stopCluster(cl)
    rep_data[[r]] <- data_matrix
  }

  aligns <- Reduce(cbind, rep_data)
  if (is.null(dim(aligns))) {
    aligns <- matrix(aligns, ncol = 1)
  }
  mean_aligns <- apply(aligns, 1, mean)

  time_elapsed <- difftime(Sys.time(), time_start, units = "auto")
  cat(paste("\nCompleted in:", as.double(time_elapsed), units(time_elapsed)))
  # make dataframe
  df_al <- data.frame(align = mean_aligns, lambda = lambda.test)

  p1 <- ggplot(df_al, aes(x = lambda, y = mean_aligns)) + geom_line(size=1) +
    geom_point() +
    theme_classic() + labs(y = 'Alignment', x = 'Lambda') +
    guides(col = guide_legend(title = "", override.aes = list(size = 2))) +
    theme(legend.position = 'top')

  if (return.data) {
    print(p1)
    if (return.raw) {
      rownames(aligns) <- lambda.test
      return(aligns)
    }
    return(df_al)
  }
  return(p1)
}

#' Visually suggest appropiate k value
#'
#' @description
#' This can be used to select appropriate value of k for factorization of particular dataset.
#' Plots median (across cells in all datasets) K-L divergence from uniform for cell factor loadings
#' as a function of k. This should increase as k increases but is expected to level off above
#' sufficiently high number of factors (k). This is because cells should have factor loadings which
#' are not uniformly distributed when an appropriate number of factors is reached.
#'
#' Depending on number of cores used, this process can take 10-20 minutes.
#'
#' @param object \code{liger} object. Should normalize, select genes, and scale before calling.
#' @param k.test Set of factor numbers to test (default seq(5, 50, 5)).
#' @param lambda Lambda to use for all foctorizations (default 5).
#' @param thresh Convergence threshold. Convergence occurs when |obj0-obj|/(mean(obj0,obj)) < thresh
#' @param max.iters Maximum number of block coordinate descent iterations to perform
#' @param num.cores Number of cores to use for optimizing factorizations in parallel (default 1)
#' @param rand.seed Random seed for reproducibility (default 1).
#' @param gen.new Do not use optimizeNewK in factorizations. Results in slower factorizations.
#'   (default FALSE).
#' @param nrep Number restarts to perform at each k value tested (increase to produce
#'   smoother curve if results unclear) (default 1).
#' @param plot.log2 Plot log2 curve for reference on K-L plot (log2 is upper bound and con
#'   sometimes help in identifying "elbow" of plot). (default TRUE)
#' @param return.data Whether to return list of data matrices (raw) or dataframe (processed)
#'   instead of ggplot object (default FALSE).
#' @param return.raw If return.results TRUE, whether to return raw data (in format described below),
#'   or dataframe used to produce ggplot object. Raw data is list of matrices of K-L divergences
#'   (length(k.test) by n_cells). Length of list corresponds to nrep. (default FALSE)
#'
#' @return Matrix of results if indicated or ggplot object. Plots K-L divergence vs. k to console.
#' @import doSNOW
#' @importFrom foreach foreach
#' @importFrom foreach "%dopar%"
#' @importFrom ggplot2 ggplot aes geom_point geom_line guides guide_legend labs theme theme_classic
#' @export
#' @examples
#' \dontrun{
#' Y <- matrix(c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12), nrow = 4, byrow = T)
#' Z <- matrix(c(1, 2, 3, 4, 5, 6, 7, 6, 5, 4, 3, 2), nrow = 4, byrow = T)
#' ligerex <- createLiger(list(y_set = Y, z_set = Z))
#' ligerex <- normalize(ligerex)
#' ligerex <- selectGenes(ligerex)
#' ligerex <- scaleNotCenter(ligerex)
#' # examine plot for most appropriate k, use multiple cores for faster results
#' suggestK(ligerex, num.cores = 4)
#' }

suggestK <- function(object, k.test = seq(5, 50, 5), lambda = 5, thresh = 1e-4, max.iters = 100,
                     num.cores = 1, rand.seed = 1, gen.new = F, nrep = 1, plot.log2 = T,
                     return.data = F, return.raw = F) {
  if (length(object@scale.data) == 0) {
    stop("scaleNotCenter should be run on the object before running suggestK.")
  }
  time_start <- Sys.time()
  # optimize largest k value first to take advantage of efficient updating
  print("This operation may take several minutes depending on number of values being tested")
  rep_data <- list()
  for (r in 1:nrep) {
    print(paste0("Preprocessing for rep ", r,
                 ": optimizing initial factorization with largest test k=",
                 k.test[length(k.test)]))
    object <- optimizeALS(object, k = k.test[length(k.test)], lambda = lambda, thresh = thresh,
                          max.iters = max.iters, nrep = 1, rand.seed = (rand.seed + r - 1))
    print('Progress now represents completed factorizations (out of total number of k values)')
    cl <- makeCluster(num.cores)
    registerDoSNOW(cl)
    pb <- txtProgressBar(min = 0, max = length(k.test), style = 3, initial = 1, file = "")
    # define progress bar function
    progress <- function(n) setTxtProgressBar(pb, n)
    opts <- list(progress = progress)
    data_matrix <- foreach(i = length(k.test):1, .combine = "rbind", .options.snow = opts,
                           .packages = 'liger') %dopar% {
       if (i != length(k.test)) {
         if (gen.new) {
           ob.test <- optimizeALS(object,
                                  k = k.test[i], lambda = lambda, thresh = thresh,
                                  max.iters = max.iters, rand.seed = (rand.seed + r - 1)
           )
         } else {
           ob.test <- optimizeNewK(object,
                                   k.new = k.test[i], lambda = lambda, thresh = thresh,
                                   max.iters = max.iters, rand.seed = (rand.seed + r - 1)
           )
         }
       } else {
         ob.test <- object
       }
       dataset_split <- kl_divergence_uniform(ob.test)
       unlist(dataset_split)
    }
    close(pb)
    stopCluster(cl)
    data_matrix <- data_matrix[nrow(data_matrix):1, ]
    rep_data[[r]] <- data_matrix
  }

  medians <- Reduce(cbind, lapply(rep_data, function(x) {apply(x, 1, median)}))
  if (is.null(dim(medians))) {
    medians <- matrix(medians, ncol = 1)
  }
  mean_kls <- apply(medians, 1, mean)

  time_elapsed <- difftime(Sys.time(), time_start, units = "auto")
  cat(paste("\nCompleted in:", as.double(time_elapsed), units(time_elapsed)))
  # make dataframe
  df_kl <- data.frame(median_kl = c(mean_kls, log2(k.test)), k = c(k.test, k.test),
                      calc = c(rep('KL_div', length(k.test)), rep('log2(k)', length(k.test))))
  if (!plot.log2) {
    df_kl <- df_kl[df_kl$calc == 'KL_div', ]
  }

  p1 <- ggplot(df_kl, aes(x = k, y = median_kl, col = calc)) + geom_line(size=1) +
    geom_point() +
    theme_classic() + labs(y='Median KL divergence (across all cells)', x = 'K') +
    guides(col=guide_legend(title="", override.aes = list(size = 2))) +
    theme(legend.position = 'top')

  if (return.data) {
    print(p1)
    if (return.raw) {
      rep_data <- lapply(rep_data, function(x) {
        rownames(x) <- k.test
        return(x)
      })
      return(rep_data)
    }
    return(df_kl)
  }
  return(p1)
}


#######################################################################################
#### Quantile Alignment/Normalization

#' Quantile align (normalize) factor loadings
#'
#' This process builds a shared factor neighborhood graph to jointly cluster cells, then quantile
#' normalizes corresponding clusters.
#'
#' The first step, building the shared factor neighborhood graph, is performed in SNF(), and
#' produces a graph representation where edge weights between cells (across all datasets)
#' correspond to their similarity in the shared factor neighborhood space. An important parameter
#' here is knn_k, the number of neighbors used to build the shared factor space (see SNF()). Afterwards,
#' modularity-based community detection is performed on this graph (Louvain clustering) in order
#' to identify shared clusters across datasets. The method was first developed by Waltman and van Eck
#' (2013) and source code is available at http://www.ludowaltman.nl/slm/. The most important parameter
#' here is resolution, which corresponds to the number of communities detected.
#'
#' Next we perform quantile alignment for each dataset, factor, and cluster (by
#' stretching/compressing datasets' quantiles to better match those of the reference dataset). These
#' aligned factor loadings are combined into a single matrix and returned as H.norm.
#'
#' @param object \code{liger} object. Should run optimizeALS before calling.
#' @param knn_k Number of nearest neighbors for within-dataset knn graph (default 20).
#' @param k2 Horizon parameter for shared nearest factor graph. Distances to all but the k2 nearest
#'   neighbors are set to 0 (cuts down on memory usage for very large graphs). (default 500)
#' @param prune.thresh Minimum allowed edge weight. Any edges below this are removed (given weight
#'  0) (default 0.2)
#' @param ref_dataset Name of dataset to use as a "reference" for normalization. By default,
#'   the dataset with the largest number of cells is used.
#' @param min_cells Minimum number of cells to consider a cluster shared across datasets (default 2)
#' @param quantiles Number of quantiles to use for quantile normalization (default 50).
#' @param nstart Number of times to perform Louvain community detection with different random
#'   starts (default 10).
#' @param resolution Controls the number of communities detected. Higher resolution -> more
#'   communities. (default 1)
#' @param dims.use Indices of factors to use for shared nearest factor determination (default
#'   1:ncol(H[[1]])).
#' @param dist.use Distance metric to use in calculating nearest neighbors (default "CR").
#' @param center Centers the data when scaling factors (useful for less sparse modalities like
#'   methylation data). (default FALSE)
#' @param small.clust.thresh Extracts small clusters loading highly on single factor with fewer
#'   cells than this before regular alignment (default 0 -- no small cluster extraction).
#' @param id.number Number to use for identifying edge file (when running in parallel)
#'   (generates random value by default).
#' @param print.mod Print modularity output from clustering algorithm (default FALSE).
#' @param print.align.summary Print summary of clusters which did not align normally (default FALSE).
#' @param ... Arguments passed to other methods
#'
#' @return \code{liger} object with H.norm slot set.
#' @export
#'
#' @examples
#' \dontrun{
#' # liger object, factorization complete
#' ligerex
#' # do basic quantile alignment
#' ligerex <- quantileAlignSNF(ligerex)
#' # higher resolution for more clusters (note that SNF is conserved)
#' ligerex <- quantileAlignSNF(ligerex, resolution = 1.2)
#' # change knn_k for more fine-grained local clustering
#' ligerex <- quantileAlignSNF(ligerex, knn_k = 15, resolution = 1.2)
#' }
#'
quantileAlignSNF <- function(
  object,
  ...
) {
  UseMethod(generic = 'quantileAlignSNF', object = object)
}

#' @param snf Output from \code{\link{SNF}}
#' @param cell.names A vector of cell names
#' @param ref_dataset Name or index of reference dataset
#'
#' @rdname quantileAlignSNF
#' @export
#' @method quantileAlignSNF list
#'
quantileAlignSNF.list <- function(
  object,
  snf,
  cell.names,
  ref_dataset,
  prune.thresh = 0.2,
  min_cells = 2,
  quantiles = 50,
  nstart = 10,
  resolution = 1,
  center = FALSE,
  id.number = NULL,
  print.mod = FALSE,
  print.align.summary = FALSE,
  ...
) {
  if (!all(sapply(X = object, FUN = is.matrix))) {
    stop("All values in 'object' must be a matrix")
  }
  if (is.null(x = names(x = object))) {
    stop("'objec' must be a named list of matrices")
  }
  if (!(is.list(x = snf) && !is.data.frame(x = snf))) {
    stop("'snf' must be a list")
  }
  snf.names <- c('cells.cl', 'idents', 'out.summary')
  if (!all(sort(x = names(x = snf)) %in% sort(x = snf.names))) {
    stop("'snf' must have the following names: ", paste(snf.names, collapse = ','))
  }
  if (is.character(x = ref_dataset) && !ref_dataset %in% names(x = object)) {
    stop("Cannot find reference dataset")
  } else if (!inherits(x = 'stim', what = c('character', 'numeric'))) {
    stop("'ref_dataset' must be a character or integer specifying which dataset is the reference")
  }
  if (is.null(x = id.number)) {
    set.seed(seed = NULL)
    id.number <- sample(x = 1000000:9999999, size = 1)
  }
  idents <- snf$idents
  Hs <- object
  idents.rest <- SLMCluster(
    edge = snf$out.summary,
    nstart = nstart,
    R = resolution,
    prune.thresh = prune.thresh,
    id.number = id.number,
    print.mod = print.mod
  )
  names(x = idents.rest) <- setdiff(x = cell.names, y = snf$cells.cl)
  # Especially when datasets are large, SLM generates a fair number of singletons.
  # To assign these to a cluster, take mode of the cluster assignments of within-dataset neighbors
  if (min(table(idents.rest)) == 1) {
    idents.rest <- assign.singletons.list(
      object = object,
      idents = idents.rest,
      center = center
    )
  }
  idents[names(x = idents.rest)] <- as.character(x = idents.rest)
  idents <- factor(x = idents)
  names(x = idents) <- cell.names
  cs <- cumsum(x = c(0, sapply(X = Hs, FUN = nrow)))
  clusters <- lapply(
    X = 1:length(x = Hs),
    FUN = function(i) {
      idx <- cs[i] + 1:nrow(x = Hs[[i]])
      return(idents[idx])
    }
  )
  names(x = clusters) <- names(x = Hs)
  dims <- ncol(x = Hs[[ref_dataset]])
  too.few <- vector(mode = 'list', length = length(x = Hs))
  names(x = too.few) <- names(x = Hs)
  for (k in 1:length(x = Hs)) {
    for (i in 1:dims) {
      for (j in levels(x = idents)) {
        if (sum(clusters[[ref_dataset]] == j, na.rm = TRUE) < min_cells || sum(clusters[[k]] == j, na.rm = TRUE) < min_cells) {
          too.few[[names(x = Hs)[k]]] <- c(too.few[[names(x = Hs)[k]]], j)
          next
        } else if (sum(clusters[[k]] == j, na.rm = TRUE) == 1) {
          Hs[[k]][clusters[[k]] == j, i] <- mean(x = Hs[[ref_dataset]][clusters[[ref_dataset]] == j, i])
          too.few[[names(x = Hs)[k]]] <- c(too.few[[names(x = Hs)[k]]], j)
          next
        }
        q2 <- quantile(
          x = Hs[[k]][clusters[[k]] == j, i],
          probs = seq(0, 1, by = 1 / quantiles),
          na.rm = T
        )
        q1 <- quantile(
          x = Hs[[ref_dataset]][clusters[[ref_dataset]] == j, i],
          probs = seq(from = 0, to = 1, by = 1 / quantiles),
          na.rm = TRUE
        )
        if (sum(q1) == 0 | sum(q2) == 0 | length(x = unique(x = q1)) < 2 | length(x = unique(x = q2)) < 2) {
          new_vals <- rep(0, sum(clusters[[k]] == j))
        } else {
          warp_func <- approxfun(x = q2, y = q1)
          new_vals <- warp_func(Hs[[k]][clusters[[k]] == j, i])
        }
        if (anyNA(x = new_vals)) {
          stop("Select lower resolution; too many communities detected.")
        }
        Hs[[k]][clusters[[k]] == j, i] <- new_vals
      }
    }
  }
  if (print.align.summary && length(x = unlist(x = too.few)) > 0) {
    print("Summary:")
    for (i in 1:length(x = Hs)) {
      print(paste(
        "In dataset",
        names(x = Hs)[i],
        "these clusters did not align normally (too few cells):"
      ))
      print(x = unique(x = too.few[[names(x = Hs)[i]]]))
    }
  }
  out <- list(
    'H.norm' = Reduce(f = rbind, x = Hs),
    'alignment.clusters' = idents,
    'clusters' = idents
  )
  return(out)
}

#' @rdname quantileAlignSNF
#' @export
#' @method quantileAlignSNF liger
#'
quantileAlignSNF.liger <- function(
  object,
  knn_k = 20,
  k2 = 500,
  prune.thresh = 0.2,
  ref_dataset = NULL,
  min_cells = 2,
  quantiles = 50,
  nstart = 10,
  resolution = 1,
  dims.use = 1:ncol(x = object@H[[1]]),
  dist.use = 'CR',
  center = FALSE,
  small.clust.thresh = 0,
  id.number = NULL,
  print.mod = FALSE,
  print.align.summary = FALSE,
  ...
) {
  if (is.null(x = ref_dataset)) {
    ns <- sapply(X = object@scale.data, FUN = nrow)
    ref_dataset <- names(x = object@scale.data)[which.max(x = ns)]
  }
  if (!isTRUE(object@parameters[["knn_k"]] == knn_k) |
      !isTRUE(object@parameters[["k2"]] == k2) |
      !isTRUE(object@parameters[["dist.use"]] == dist.use) |
      !isTRUE(object@parameters[["SNF_center"]] == center) |
      !isTRUE(identical(object@parameters[["dims.use"]], dims.use)) |
      !isTRUE(object@parameters[["small.clust.thresh"]] == small.clust.thresh)) {
    print("Recomputing shared nearest factor space")
    object <- SNF(
      object = object,
      knn_k = knn_k,
      k2 = k2,
      dist.use = dist.use,
      center = center,
      dims.use = dims.use,
      small.clust.thresh = small.clust.thresh
    )
  }
  out <- quantileAlignSNF(
    object = object@H,
    snf = object@snf,
    cell.names = unlist(x = lapply(X = object@scale.data, FUN = rownames)),
    ref_dataset = ref_dataset,
    prune.thresh = prune.thresh,
    min_cells = min_cells,
    quantiles = quantiles,
    nstart = nstart,
    resolution = resolution,
    center = center,
    id.number = id.number,
    print.mod = print.mod,
    print.align.summary = print.align.summary
  )
  for (i in names(x = out)) {
    slot(object = object, name = i) <- out[[i]]
  }
  object@parameters$ref_dataset <- ref_dataset
  object@parameters$knn_k <- knn_k
  object@parameters$k2 <- k2
  object@parameters$prune.thresh <- prune.thresh
  object@parameters$min_cells <- min_cells
  object@parameters$dims.use <- dims.use
  object@parameters$dist.use <- dist.use
  object@parameters$SNF_center <- center
  object@parameters$small.clust.thresh <- small.clust.thresh
  object@parameters$resolution <- resolution
  return(object)
}

#' Generate shared factor neighborhood graph
#'
#' @description
#' Builds shared factor neighborhood graph representation of all cells in analysis. The first step
#' is to scale factor loadings across each cell for each factor. This corresponds to scaling (by L2
#' norm or similar) the columns of the H matrices, and allows us for subsequent comparison across
#' factors in a cell's loadings. The max factor for each cell is computed.
#'
#' The next step is to determine the knn_k nearest neighbors (within the same dataset) for each cell
#' based on the cells' factor loadings. For each cell, we count the number of neighbors with max
#' factor loadings for each factor.
#'
#' This creates a shared space across datasets based on the max factor neighborhoods -- we now find
#' the nearest k2 neighbors and their corresponding distances across all datasets. We rescale these
#' distances into edge weights where an edge weight of 1 corresponds to minimal distance and 0
#' corresponds to the max distance.
#'
#' @param dims.use Indices of factors to use for shared nearest factor determination (default
#'   1:ncol(H[[1]])).
#' @param dist.use Distance metric to use in calculating nearest neighbors (default "CR").
#' @param center Centers the data when scaling factors (useful for less sparse modalities like
#'   methylation data). (default FALSE)
#' @param knn_k Number of nearest neighbors for within-dataset knn graph (default 20).
#' @param k2 Horizon parameter for shared nearest factor graph. Distances to all but the k2 nearest
#'   neighbors are set to 0 (cuts down on memory usage for very large graphs). (default 500)
#' @param small.clust.thresh Extracts small clusters loading highly on single factor with fewer
#'   cells than this before regular alignment (default 0 -- no small cluster extraction).
#' @param ... Arguments passed to and from other methods
#'
#' @return List of three values. First is names of cells identified in small cluster extraction,
#'   second is vector of cluster identities where only small cluster identities are not "NA", third
#'   is the edge weight representation of the shared factor neighborhood graph.
#'
#' @export
#' @importFrom RANN.L1 nn2
#' @importFrom FNN get.knn
#'
#' @examples
#' \dontrun{
#' # liger object, factorization complete
#' ligerex
#' # get SNF graph (third element)
#' SNF_graph <- SNF(ligerex, knn_k = 15)[[3]]
#' }
#'
SNF <- function(object, ...) {
  UseMethod(generic = 'SNF', object = object)
}

#' @rdname SNF
#' @export
#' @method SNF list
#'
SNF.list <- function(
  object,
  dims.use = 1:ncol(x = object[[1]]),
  dist.use = "CR",
  center = FALSE,
  knn_k = 20,
  k2 = 500,
  small.clust.thresh = knn_k,
  ...
) {
  NN.maxes <- do.call(
    what = rbind,
    args = lapply(
      X = 1:length(x = object),
      FUN = function(i) {
        sc <- scale(x = object[[i]], center = center, scale = TRUE)
        maxes <- factor(
          x = apply(X = sc[, dims.use], MARGIN = 1, FUN = which.max),
          levels = 1:ncol(sc)
        )
        if (dist.use == "CR") {
          norm <- t(x = apply(X = object[[i]][, dims.use], MARGIN = 1, FUN = scaleL2norm))
          if (any(is.na(x = norm))) {
            stop(paste(
              "Unable to normalize loadings for all cells; some cells",
              "loading on no selected factors."
            ))
          }
        } else {
          norm <- object[[i]][, dims.use]
        }
        knn.idx <- get.knn(data = norm, k = knn_k, algorithm = dist.use)$nn.index
        t(x = apply(
          X = knn.idx,
          MARGIN = 1,
          FUN = function(q) {
            return(table(maxes[q]))
          }
        ))
      }
    ))
  rownames(x = NN.maxes) <- unlist(x = lapply(X = object, FUN = rownames))
  # extract small clusters
  if (small.clust.thresh > 0) {
    print(paste0(
      "Isolating small clusters with fewer than ", small.clust.thresh,
      " members"
    ))
  }
  max.val <- factor(x = apply(X = NN.maxes, MARGIN = 1, FUN = which.max))
  names(x = max.val) <- rownames(x = NN.maxes)
  idents <- rep.int(x = "NA", times = nrow(x = NN.maxes))
  names(x = idents) <- rownames(x = NN.maxes)
  cl <- levels(x = max.val)[which(x = table(max.val) < small.clust.thresh)]
  cells.cl <- names(x = max.val)[which(x = max.val %in% cl)]
  idents[cells.cl] <- paste0("F", as.character(x = max.val[cells.cl]))
  nn.obj <- nn2(
    data = NN.maxes[setdiff(x = rownames(x = NN.maxes), y = cells.cl), ],
    k = k2
  )
  out.snn <- 1 - (nn.obj$nn.dists / (2 * knn_k))
  out.summary <- matrix(ncol = 3, nrow = (ncol(x = out.snn) * nrow(x = out.snn)))
  counter <- 1
  for (i in 1:nrow(x = out.snn)) {
    for (j in 1:ncol(x = out.snn)) {
      out.summary[counter, ] <- c(
        i, nn.obj$nn.idx[i, j],
        out.snn[i, j]
      )
      counter <- counter + 1
    }
  }
  out.summary[out.summary[, 1] == out.summary[, 2], 3] <- 0
  out.summary[, 1] <- out.summary[, 1] - 1
  out.summary[, 2] <- out.summary[, 2] - 1
  # idents returned here only contain values for small clusters
  return(list(cells.cl = cells.cl, idents = idents, out.summary = out.summary))
}

#' @rdname SNF
#' @export
#' @method SNF liger
#'
SNF.liger <- function(
  object,
  dims.use = 1:ncol(x = object@H[[1]]),
  dist.use = "CR",
  center = FALSE,
  knn_k = 20,
  k2 = 500,
  small.clust.thresh = knn_k,
  ...
) {
  object@snf <- SNF(
    object = object@H,
    dims.use = dims.use,
    dist.use = dist.use,
    center = center,
    knn_k = knn_k,
    k2 = k2,
    small.clust.thresh = small.clust.thresh,
    ...
  )
  return(object)
}

#######################################################################################
#### Dimensionality Reduction

#' Perform t-SNE dimensionality reduction
#'
#' Runs t-SNE on the normalized cell factors (or raw cell factors) to generate a 2D embedding for
#' visualization. Has option to run on subset of factors. Note that running multiple times will
#' reset tsne.coords values.
#'
#' In order to run fftRtsne (recommended for large datasets), you must first install FIt-SNE as
#' detailed \href{https://github.com/KlugerLab/FIt-SNE}{here}. Include the path to the cloned
#' FIt-SNE directory as the fitsne.path parameter, though this is only necessary for the first call
#' to runTSNE. For more detailed FIt-SNE installation instructions, see the liger repo README.
#'
#' @param object \code{liger} object. Should run quantileAlignSNF before calling with defaults.
#' @param use.raw Whether to use un-aligned cell factor loadings (H matrices) (default FALSE).
#' @param dims.use Factors to use for computing tSNE embedding (default 1:ncol(H.norm)).
#' @param use.pca Whether to perform initial PCA step for Rtsne (default FALSE).
#' @param perplexity Parameter to pass to Rtsne (expected number of neighbors) (default 30).
#' @param theta Speed/accuracy trade-off (increase for less accuracy), set to 0.0 for exact TSNE
#'   (default 0.5).
#' @param method Supports two methods for estimating tSNE values: Rtsne (Barnes-Hut implementation
#'   of t-SNE) and fftRtsne (FFT-accelerated Interpolation-based t-SNE) (using Kluger Lab
#'   implementation). (default Rtsne)
#' @param fitsne.path Path to the cloned FIt-SNE directory (ie. '/path/to/dir/FIt-SNE') (required
#'   for using fftRtsne -- only first time runTSNE is called) (default NULL).
#' @param rand.seed Random seed for reproducibility (default 42).
#'
#' @return \code{liger} object with dr.coords[["tsne"]] slot set.
#' @importFrom Rtsne Rtsne
#' @export
#' @examples
#' \dontrun{
#'  # liger object
#' ligerex
#' # generate H.norm by quantile aligning factor loadings
#' ligerex <- quantileAlignSNF(ligerex)
#' # get tsne.coords for normalized data
#' ligerex <- runTSNE(ligerex)
#' # get tsne.coords for raw factor loadings
#' ligerex <- runTSNE(ligerex, use.raw = T)
#' }

runTSNE <- function(object, use.raw = F, dims.use = 1:ncol(object@H.norm), use.pca = F,
                    perplexity = 30, theta = 0.5, method = 'Rtsne', fitsne.path = NULL,
                    rand.seed = 42) {
  if (use.raw) {
    data.use <- do.call(rbind, object@H)
    if (identical(dims.use, 1:0)) {
      dims.use <- 1:ncol(data.use)
    }
  } else {
    data.use <- object@H.norm
  }
  if (method == 'Rtsne') {
    set.seed(rand.seed)
    object@dr.coords[["tsne"]] <- Rtsne(data.use[, dims.use], pca = use.pca, check_duplicates = F,
                                theta = theta, perplexity = perplexity)$Y
  } else if (method == 'fftRtsne') {
    if (!exists('fftRtsne')) {
      if (is.null(fitsne.path)) {
        stop('Please pass in path to FIt-SNE directory as fitsne.path.')
      }
      source(paste0(fitsne.path, '/fast_tsne.R'), chdir = T)
    }
    object@dr.coords[["tsne"]] <- fftRtsne(data.use[, dims.use], rand_seed = rand.seed,
                                   theta = theta, perplexity = perplexity)
  } else {
    stop('Invalid method: Please choose Rtsne or fftRtsne')
  }
  rownames(object@dr.coords[["tsne"]]) <- rownames(data.use)
  return(object)
}

#' Perform UMAP dimensionality reduction
#'
#' @description
#' Run UMAP on the normalized cell factors (or raw cell factors) to generate a 2D embedding for
#' visualization (or general dimensionality reduction). Has option to run on subset of factors.
#' Note that running multiple times will overwrite tsne.coords values. It is generally
#' recommended to use this method for dimensionality reduction with extremely large datasets.
#'
#' Note that this method requires that the package reticulate is installed, along with the Python
#' package umap-learn.
#'
#' @param object \code{liger} object. Should run quantileAlignSNF before calling with defaults.
#' @param use.raw Whether to use un-aligned cell factor loadings (H matrices) (default FALSE).
#' @param dims.use Factors to use for computing tSNE embedding (default 1:ncol(H.norm)).
#' @param k Number of dimensions to reduce to (default 2).
#' @param distance Mtric used to measure distance in the input space. A wide variety of metrics are
#'   already coded, and a user defined function can be passed as long as it has been JITd by numba.
#'   (default "euclidean")
#' @param n_neighbors Number of neighboring points used in local approximations of manifold
#'   structure. Larger values will result in more global structure being preserved at the loss of
#'   detailed local structure. In general this parameter should often be in the range 5 to 50, with
#'   a choice of 10 to 15 being a sensible default. (default 10)
#' @param min_dist Controls how tightly the embedding is allowed compress points together. Larger
#'   values ensure embedded points are more evenly distributed, while smaller values allow the
#'   algorithm to optimise more accurately with regard to local structure. Sensible values are in
#'   the range 0.001 to 0.5, with 0.1 being a reasonable default. (default 0.1)
#' @param rand.seed Random seed for reproducibility (default 42).
#'
#' @return \code{liger} object with dr.coords[["umap"]] slot set.
#' @export
#' @examples
#' \dontrun{
#'  # liger object with factorization complete
#' ligerex
#' # generate H.norm by quantile aligning factor loadings
#' ligerex <- quantileAlignSNF(ligerex)
#' # get tsne.coords for normalized data
#' ligerex <- runUMAP(ligerex)
#' # get tsne.coords for raw factor loadings
#' ligerex <- runUMAP(ligerex, use.raw = T)
#' }

runUMAP <- function(object, use.raw = F, dims.use = 1:ncol(object@H.norm), k=2,
                    distance = "euclidean", n_neighbors = 10, min_dist = 0.1, rand.seed = 42) {
  if (!require("reticulate", quietly = TRUE)) {
    stop(paste("Package \"reticulate\" needed for this function to work. Please install it.\n",
               "Also ensure Python package umap (PyPI name umap-learn) is installed in python",
               "version accesible to reticulate."),
         call. = FALSE)
  }
  set.seed(rand.seed)
  reticulate::py_set_seed(rand.seed)
  UMAP <- reticulate::import("umap")
  umapper <- UMAP$UMAP(
    n_components = as.integer(k), metric = distance,
    n_neighbors = as.integer(n_neighbors), min_dist = min_dist
  )
  Rumap <- umapper$fit_transform
  if (use.raw) {
    raw.data <- do.call(rbind, object@H)
    # if H.norm not set yet
    if (identical(dims.use, 1:0)) {
      dims.use <- 1:ncol(raw.data)
    }
    object@dr.coords[["umap"]] <- Rumap(raw.data[, dims.use])
    rownames(object@dr.coords[["umap"]]) <- rownames(raw.data)
  } else {
    object@dr.coords[["umap"]] <- Rumap(object@H.norm[, dims.use])
    rownames(object@dr.coords[["umap"]]) <- rownames(object@H.norm)
  }
  return(object)
}

#######################################################################################
#### Metrics

#' Calculate a dataset-specificity score for each factor
#'
#' This score represents the relative magnitude of the dataset-specific components of each factor's
#' gene loadings compared to the shared components for two datasets. First, for each dataset we
#' calculate the norm of the sum of each factor's shared loadings (W) and dataset-specific loadings
#' (V). We then determine the ratio of these two values and subtract from 1... TODO: finish
#' description.
#'
#' @param object \code{liger} object. Should run optimizeALS before calling.
#' @param dataset1 Name of first dataset (by default takes first two datasets for dataset1 and 2)
#' @param dataset2 Name of second dataset
#' @param do.plot Display barplot of dataset specificity scores (by factor) (default TRUE).
#'
#' @return List containing three elements. First two elements are the norm of each metagene factor
#' for each dataset. Last element is the vector of dataset specificity scores.
#' @export
#' @examples
#' \dontrun{
#' # liger object, factorization complete
#' ligerex
#' ligerex <- quantileAlignSNF(ligerex)
#' dataset_spec <- calcDatasetSpecificity(ligerex, do.plot = F)
#' }

calcDatasetSpecificity <- function(object, dataset1 = NULL, dataset2 = NULL, do.plot = T) {
  if (is.null(dataset1) | is.null(dataset2)) {
    dataset1 <- names(object@H)[1]
    dataset2 <- names(object@H)[2]
  }
  k <- ncol(object@H[[1]])
  pct1 <- rep(0, k)
  pct2 <- rep(0, k)
  for (i in 1:k) {
    pct1[i] <- norm(as.matrix(object@V[[dataset1]][i, ] + object@W[i, ]), "F")
    # norm(object@H[[1]][,i] %*% t(object@W[i,] + object@V[[1]][i,]),"F")
    pct2[i] <- norm(as.matrix(object@V[[dataset2]][i, ] + object@W[i, ]), "F")
    # norm(object@H[[2]][,i] %*% t(object@W[i,] + object@V[[2]][i,]),"F")
  }
  # pct1 = pct1/sum(pct1)
  # pct2 = pct2/sum(pct2)
  if (do.plot) {
    barplot(100 * (1 - (pct1 / pct2)),
            xlab = "Factor",
            ylab = "Percent Specificity", main = "Dataset Specificity of Factors",
            names.arg = 1:k, cex.names = 0.75, mgp = c(2, 0.5, 0)
    ) # or possibly abs(pct1-pct2)
  }
  return(list(pct1, pct2, 100 * (1 - (pct1 / pct2))))
}

#' Calculate agreement metric
#'
#' @description
#' This metric quantifies how much the factorization and alignment distorts the geometry of the
#' original datasets. The greater the agreement, the less distortion of geometry there is. This is
#' calculated by performing dimensionality reduction on the original and quantile aligned (or just
#' factorized) datasets, and measuring similarity between the k nearest neighbors for each cell in
#' original and aligned datasets. The Jaccard index is used to quantify similarity, and is the final
#' metric averages across all cells.
#'
#' Note that for most datasets, the greater the chosen k, the greater the agreement in general.
#' There are several options for dimensionality reduction, with the default being 'NMF' as it is
#' expected to be most similar to iNMF. Although agreement can theoretically approach 1, in practice
#' it is usually no higher than 0.2-0.3 (particularly for non-deterministic approaches like NMF).
#'
#' @param object \code{liger} object. Should call quantileAlignSNF before calling.
#' @param dr.method Dimensionality reduction method to use for assessing pre-alignment geometry
#'   (either "PCA", "NMF", or "ICA"). (default "NMF")
#' @param ndims Number of dimensions to use in dimensionality reduction (recommended to use the
#'   same as number of factors) (default 40).
#' @param k Number of nearest neighbors to use in calculating Jaccard index (default 15).
#' @param use.aligned Whether to use quantile aligned or unaligned cell factor loadings (default
#'   TRUE).
#' @param rand.seed Random seed for reproducibility (default 42).
#' @param by.dataset Return agreement calculated for each dataset (default FALSE).
#'
#' @return Agreement metric (or vector of agreement per dataset).
#' @importFrom FNN get.knn
#' @importFrom ica icafast
#' @importFrom irlba prcomp_irlba
#' @export
#' @examples
#' \dontrun{
#' # liger object, factorization complete
#' ligerex
#' ligerex <- quantileAlignSNF(ligerex)
#' agreement <- calcAgreement(ligerex, dr.method = "NMF")
#' }

calcAgreement <- function(object, dr.method = "NMF", ndims = 40, k = 15, use.aligned = TRUE,
                          rand.seed = 42, by.dataset = FALSE) {
  if (!require("NNLM", quietly = TRUE) & dr.method == "NMF") {
    stop("Package \"NNLM\" needed for this function to perform NMF. Please install it.",
         call. = FALSE
    )
  }

  print(paste("Reducing dimensionality using", dr.method))
  set.seed(rand.seed)
  dr <- list()
  if (dr.method == "NMF") {
    dr <- lapply(object@scale.data, function(x) {
      nnmf(x, k = ndims)$W
    })
  }
  else if (dr.method == "ICA") {
    dr <- lapply(object@scale.data, function(x) {
      icafast(x, nc = ndims)$S
    })
  } else {
    dr <- lapply(object@scale.data, function(x) {
      suppressWarnings(prcomp_irlba(t(x),
                                    n = ndims,
                                    scale. = (colSums(x) > 0), center = F
      )$rotation)
    })
    for (i in 1:length(dr)) {
      rownames(dr[[i]]) <- rownames(object@scale.data[[i]])
    }
  }
  ns <- sapply(object@scale.data, nrow)
  n <- sum(ns)
  jaccard_inds <- c()
  distorts <- c()

  for (i in 1:length(dr)) {
    jaccard_inds_i <- c()
    if (use.aligned) {
      original <- object@H.norm[rownames(dr[[i]]), ]
    } else {
      original <- object@H[[i]]
    }
    fnn.1 <- get.knn(dr[[i]], k = k)
    fnn.2 <- get.knn(original, k = k)
    jaccard_inds_i <- c(jaccard_inds_i, sapply(1:ns[i], function(i) {
      intersect <- intersect(fnn.1$nn.index[i, ], fnn.2$nn.index[i, ])
      union <- union(fnn.1$nn.index[i, ], fnn.2$nn.index[i, ])
      length(intersect) / length(union)
    }))
    jaccard_inds_i <- jaccard_inds_i[is.finite(jaccard_inds_i)]
    jaccard_inds <- c(jaccard_inds, jaccard_inds_i)

    distorts <- c(distorts, mean(jaccard_inds_i))
  }
  if (by.dataset) {
    return(distorts)
  }
  return(mean(jaccard_inds))
}

#' Calculate alignment metric
#'
#' This metric quantifies how well-aligned two or more datasets are. Alignment is defined as in the
#' documentation for Seurat. We randomly downsample all datasets to have as many cells as the
#' smallest one. We construct a nearest-neighbor graph and calculate for each cell how many of its
#' neighbors are from the same dataset. We average across all cells and compare to the expected
#' value for perfectly mixed datasets, and scale the value from 0 to 1. Note that in practice,
#' alignment can be greater than 1 occasionally.
#'
#' @param object \code{liger} object. Should call quantileAlignSNF before calling.
#' @param k Number of nearest neighbors to use in calculating alignment. By default, this will be
#'   floor(0.01 * total number of cells), with a lower bound of 10 in all cases except where the
#'   total number of sampled cells is less than 10.
#' @param rand.seed Random seed for reproducibility (default 1).
#' @param cells.use Vector of cells across all datasets to use in calculating alignment
#' @param cells.comp Vector of cells across all datasets to compare to cells.use when calculating
#'   alignment (instead of dataset designations). These can be from the same dataset as cells.use.
#'   (default NULL)
#' @param clusters.use Names of clusters to use in calculating alignment (default NULL).
#' @param by.cell Return alignment calculated individually for each cell (default FALSE).
#' @param by.dataset Return alignment calculated for each dataset (default FALSE).
#'
#' @return Alignment metric.
#' @importFrom FNN get.knn
#' @export
#' @examples
#' \dontrun{
#' # liger object, factorization complete
#' ligerex
#' ligerex <- quantileAlignSNF(ligerex)
#' alignment <- calcAlignment(ligerex)
#' }

calcAlignment <- function(object, k = NULL, rand.seed = 1, cells.use = NULL, cells.comp = NULL,
                          clusters.use = NULL, by.cell = F, by.dataset = F) {
  if (is.null(cells.use)) {
    cells.use <- rownames(object@H.norm)
  }
  if (!is.null(clusters.use)) {
    cells.use <- names(object@clusters)[which(object@clusters %in% clusters.use)]
  }
  if (!is.null(cells.comp)) {
    nmf_factors <- object@H.norm[c(cells.use, cells.comp), ]
    num_cells <- length(c(cells.use, cells.comp))
    func_H <- list(cells1 = nmf_factors[cells.use, ],
                   cells2 = nmf_factors[cells.comp, ])
    print('Using designated sets cells.use and cells.comp as subsets to compare')
  } else {
    nmf_factors <- object@H.norm[cells.use, ]
    num_cells <- length(cells.use)
    func_H <- lapply(seq_along(object@H), function(x) {
      cells.overlap <- intersect(cells.use, rownames(object@H[[x]]))
      if (length(cells.overlap) > 0) {
        object@H[[x]][cells.overlap, ]
      } else {
        warning(paste0("Selected subset eliminates dataset ", names(object@H)[x]),
                immediate. = T
        )
        return(NULL)
      }
    })
    func_H <- func_H[!sapply(func_H, is.null)]
  }
  num_factors <- ncol(object@H.norm)
  N <- length(func_H)
  if (N == 1) {
    warning("Alignment null for single dataset", immediate. = T)
  }
  set.seed(rand.seed)
  min_cells <- min(sapply(func_H, function(x) {
    nrow(x)
  }))
  sampled_cells <- unlist(lapply(1:N, function(x) {
    sample(rownames(func_H[[x]]), min_cells)
  }))
  max_k <- length(sampled_cells) - 1
  if (is.null(k)) {
    k <- min(max(floor(0.01 * num_cells), 10), max_k)
  } else if (k > max_k) {
    stop(paste0("Please select k <=", max_k))
  }
  knn_graph <- get.knn(nmf_factors[sampled_cells, 1:num_factors], k)
  # Generate new "datasets" for desired cell groups
  if (!is.null(cells.comp)) {
    dataset <- unlist(sapply(1:N, function(x) {
      rep(paste0('group', x), nrow(func_H[[x]]))
    }))
  } else {
    dataset <- unlist(sapply(1:N, function(x) {
      rep(names(object@H)[x], nrow(func_H[[x]]))
    }))
  }
  names(dataset) <- rownames(nmf_factors)
  dataset <- dataset[sampled_cells]
  num_sampled <- N * min_cells
  num_same_dataset <- rep(k, num_sampled)

  alignment_per_cell <- c()
  for (i in 1:num_sampled) {
    inds <- knn_graph$nn.index[i, ]
    num_same_dataset[i] <- sum(dataset[inds] == dataset[i])
    alignment_per_cell[i] <- 1 - (num_same_dataset[i] - (k / N)) / (k - k / N)
  }
  if (by.dataset) {
    alignments <- c()
    for (i in 1:N) {
      start <- 1 + (i - 1) * min_cells
      end <- i * min_cells
      alignment <- mean(alignment_per_cell[start:end])
      alignments <- c(alignments, alignment)
    }
    return(alignments)
  } else if (by.cell) {
    names(alignment_per_cell) <- sampled_cells
    return(alignment_per_cell)
  }
  return(mean(alignment_per_cell))
}

#' Calculate alignment for each cluster
#'
#' Returns alignment for each cluster in analysiss (see documentation for calcAlignment).
#'
#' @param object \code{liger} object. Should call quantileAlignSNF before calling.
#' @param rand.seed Random seed for reproducibility (default 1).
#' @param k Number of nearest neighbors in calculating alignment (see calcAlignment for default).
#'   Can pass in single value or vector with same length as number of clusters.
#' @param by.dataset Return alignment calculated for each dataset in cluster (default FALSE).
#'
#' @return Vector of alignment statistics (with names of clusters).
#' @importFrom FNN get.knn
#' @export
#' @examples
#' \dontrun{
#' # liger object, factorization complete
#' ligerex
#' ligerex <- quantileAlignSNF(ligerex)
#' # get alignment for each cluster
#' alignment_per_cluster <- calcAlignmentPerCluster(ligerex)
#' }

calcAlignmentPerCluster <- function(object, rand.seed = 1, k = NULL, by.dataset = F) {
  clusters <- levels(object@clusters)
  if (typeof(k) == "double") {
    if (length(k) == 1) {
      k <- rep(k, length(clusters))
    } else if (length(k) != length(clusters)) {
      print("Length of k does not match length of clusters")
    }
  }
  align_metrics <- sapply(seq_along(clusters), function(x) {
    calcAlignment(object,
                  k = k[x], rand.seed = rand.seed,
                  clusters.use = clusters[x],
                  by.dataset = by.dataset
    )
  })
  if (by.dataset) {
    colnames(align_metrics) <- levels(object@clusters)
    rownames(align_metrics) <- names(object@H)
  } else {
    names(align_metrics) <- levels(object@clusters)
  }
  return(align_metrics)
}

#' Calculate adjusted Rand index
#'
#' Computes adjusted Rand index for \code{liger} clustering and external clustering.
#' The Rand index ranges from 0 to 1, with 0 indicating no agreement between clusterings and 1
#' indicating perfect agreement.
#'
#' @param object \code{liger} object. Should run quantileAlignSNF before calling.
#' @param clusters.compare Clustering with which to compare (named vector).
#' @return Value of ARI
#' @importFrom mclust adjustedRandIndex
#'
#' @return Adjusted Rand index value.
#' @export
#' @examples
#' \dontrun{
#' # liger object, factorization done
#' ligerex
#' ligerex <- quantileAlignSNF(ligerex)
#' # toy clusters
#' cluster1 <- sample(c('type1', 'type2', 'type3'), ncol(ligerex@raw.data[[1]]), replace = T)
#' names(cluster1) <- colnames(ligerex@raw.data[[1]])
#' cluster2 <- sample(c('type4', 'type5', 'type6'), ncol(ligerex@raw.data[[2]]), replace = T)
#' names(cluster2) <- colnames(ligerex@raw.data[[2]])
#' # get ARI for first clustering
#' ari1 <- calcARI(ligerex, cluster1)
#' # get ARI for second clustering
#' ari2 <- calcARI(ligerex, cluster2)
#' }

calcARI <- function(object, clusters.compare) {
  if (length(clusters.compare) < length(object@clusters)) {
    print("Calculating ARI for subset of full cells")
  }
  return(adjustedRandIndex(object@clusters[names(clusters.compare)],
                           clusters.compare))
}

#' Calculate purity
#'
#' Calculates purity for \code{liger} clustering and external clustering (true clusters/classes).
#' Purity can sometimes be a more useful metric when the clustering to be tested contains more
#' subgroups or clusters than the true clusters (or classes). Purity also ranges from 0 to 1,
#' with a score of 1 representing a pure, or accurate, clustering.
#'
#' @param object \code{liger} object. Should run quantileAlignSNF before calling.
#' @param classes.compare Clustering with which to compare (named vector).
#'
#' @return Purity value.
#' @export
#' @examples
#' \dontrun{
#' # liger object, factorization done
#' ligerex
#' ligerex <- quantileAlignSNF(ligerex)
#' # toy clusters
#' cluster1 <- sample(c('type1', 'type2', 'type3'), ncol(ligerex@raw.data[[1]]), replace = T)
#' names(cluster1) <- colnames(ligerex@raw.data[[1]])
#' cluster2 <- sample(c('type4', 'type5', 'type6'), ncol(ligerex@raw.data[[2]]), replace = T)
#' names(cluster2) <- colnames(ligerex@raw.data[[2]])
#' # get ARI for first clustering
#' ari1 <- calcARI(ligerex, cluster1)
#' # get ARI for second clustering
#' ari2 <- calcARI(ligerex, cluster2)
#' }

calcPurity <- function(object, classes.compare) {
  if (length(classes.compare) < length(object@clusters)) {
    print("Calculating purity for subset of full cells")
  }
  clusters <- object@clusters[names(classes.compare)]
  purity <- sum(apply(table(classes.compare, clusters), 2, max)) / length(clusters)

  return(purity)
}

#######################################################################################
#### Visualization

#' Plot t-SNE coordinates of cells across datasets
#'
#' Generates two plots of all cells across datasets, one colored by dataset and one colored by
#' cluster. These are useful for visually examining the alignment and cluster distributions,
#' respectively. If clusters have not been set yet (quantileAlignSNF not called), will plot by
#' single color for second plot. It is also possible to pass in another clustering (as long as
#' names match those of cells).
#'
#' @param object \code{liger} object. Should call runTSNE or runUMAP before calling.
#' @param clusters Another clustering to use for coloring second plot (must have same names as
#'   clusters slot) (default NULL).
#' @param dr.method Dimensionality reduction method to reference. Should call the appropriate function
#'   (runTSNE for "tsne") or (runUMAP for "umap") first.
#' @param title Plot titles (list or vector of length 2) (default NULL).
#' @param pt.size Controls size of points representing cells (default 0.3).
#' @param text.size Controls size of plot text (cluster center labels) (default 3).
#' @param do.shuffle Randomly shuffle points so that points from same dataset are not plotted
#'   one after the other (default TRUE).
#' @param rand.seed Random seed for reproducibility of point shuffling (default 1).
#' @param axis.labels Vector of two strings to use as x and y labels respectively.
#' @param do.legend Display legend on plots (default TRUE).
#' @param legend.size Size of legend on plots (default 5).
#' @param return.plots Return ggplot plot objects instead of printing directly (default FALSE).
#'
#' @return List of ggplot plot objects (only if return.plots TRUE, otherwise prints plots to
#'   console).
#' @export
#' @importFrom ggplot2 ggplot geom_point geom_text ggtitle guides guide_legend aes theme xlab ylab 
#' @importFrom dplyr %>% group_by summarize
#' @examples
#' \dontrun{
#'  # liger object with aligned factor loadings
#' ligerex
#' # get tsne.coords for normalized data
#' ligerex <- runTSNE(ligerex)
#' # plot to console
#' plotByDatasetAndCluster(ligerex)
#' # return list of plots
#' plots <- plotByDatasetAndCluster(ligerex, return.plots = T)
#' }

plotByDatasetAndCluster <- function(object, clusters = NULL, dr.method = "tsne",title = NULL,
                                    pt.size = 0.3, text.size = 3, do.shuffle = T, rand.seed = 1,
                                    axis.labels = NULL, do.legend = T, legend.size = 5,
                                    return.plots = F) {
  tsne_df <- data.frame(object@dr.coords[[dr.method]])
  colnames(tsne_df) <- c("tsne1", "tsne2")
  tsne_df$Dataset <- unlist(lapply(1:length(object@H), function(x) {
    rep(names(object@H)[x], nrow(object@H[[x]]))
  }))
  c_names <- names(object@clusters)
  if (is.null(clusters)) {
    # if clusters have not been set yet
    if (length(object@clusters) == 0) {
      clusters <- rep(1, nrow(object@dr.coords[[dr.method]]))
      names(clusters) <- c_names <- rownames(object@dr.coords[[dr.method]])
    } else {
      clusters <- object@clusters
      c_names <- names(object@clusters)
    }
  }
  tsne_df$Cluster <- clusters[c_names]
  if (do.shuffle) {
    set.seed(rand.seed)
    idx <- sample(1:nrow(tsne_df))
    tsne_df <- tsne_df[idx, ]
  }

  p1 <- ggplot(tsne_df, aes(x = tsne1, y = tsne2, color = Dataset)) +
    geom_point(size = pt.size) +
    guides(color = guide_legend(override.aes = list(size = legend.size)))

  centers <- tsne_df %>% group_by(Cluster) %>% summarize(
    tsne1 = median(x = tsne1),
    tsne2 = median(x = tsne2)
  )
  p2 <- ggplot(tsne_df, aes(x = tsne1, y = tsne2, color = Cluster)) + geom_point(size = pt.size) +
    geom_text(data = centers, mapping = aes(label = Cluster), colour = "black", size = text.size) +
    guides(color = guide_legend(override.aes = list(size = legend.size)))

  if (!is.null(title)) {
    p1 <- p1 + ggtitle(title[1])
    p2 <- p2 + ggtitle(title[2])
  }
  if (!is.null(axis.labels)) {
    p1 <- p1 + xlab(axis.labels[1]) + ylab(axis.labels[2])
    p2 <- p2 + xlab(axis.labels[1]) + ylab(axis.labels[2])
  }
  if (!do.legend) {
    p1 <- p1 + theme(legend.position = "none")
    p2 <- p2 + theme(legend.position = "none")
  }
  if (return.plots) {
    return(list(p1, p2))
  } else {
    print(p1)
    print(p2)
  }
}

#' Plot specific feature on t-SNE coordinates
#'
#' Generates one plot for each dataset, colored by chosen feature (column) from cell.data slot.
#' Feature can be categorical (factor) or continuous.
#' Can also plot all datasets combined with by.dataset = F.
#'
#' @param object \code{liger} object. Should call runTSNE or runUMAP before calling.
#' @param feature Feature to plot (should be column from cell.data slot).
#' @param dr.method Dimensionality reduction method to reference. Should call the appropriate function
#'   (runTSNE for "tsne") or (runUMAP for "umap") first.
#' @param by.dataset Whether to generate separate plot for each dataset (default TRUE).
#' @param discrete Whether to treat feature as discrete; if left NULL will infer from column class
#'   in cell.data (if factor, treated like discrete) (default NULL).
#' @param title Plot title (default NULL).
#' @param pt.size Controls size of points representing cells (default 0.3).
#' @param text.size Controls size of plot text (cluster center labels) (default 3).
#' @param do.shuffle Randomly shuffle points so that points from same dataset are not plotted
#'   one after the other (default TRUE).
#' @param rand.seed Random seed for reproducibility of point shuffling (default 1).
#' @param do.labels Print centroid labels for categorical features (default FALSE).
#' @param axis.labels Vector of two strings to use as x and y labels respectively.
#' @param do.legend Display legend on plots (default TRUE).
#' @param legend.size Size of legend spots for discrete data (default 5).
#' @param option Colormap option to use for ggplot2's scale_color_viridis (default 'plasma').
#' @param zero.color Color to use for zero values (no expression) (default '#F5F5F5').
#' @param return.plots Return ggplot plot objects instead of printing directly (default FALSE).
#'
#' @return List of ggplot plot objects (only if return.plots TRUE, otherwise prints plots to
#'   console).
#' @export
#' @importFrom ggplot2 ggplot geom_point geom_text ggtitle aes guides guide_legend labs 
#' scale_color_viridis_c theme xlab ylab
#' @importFrom dplyr %>% group_by summarize
#' @examples
#' \dontrun{
#'  # liger object with aligned factor loadings
#' ligerex
#' # get tsne.coords for normalized data
#' ligerex <- runTSNE(ligerex)
#' # plot nUMI to console
#' plotFeature(ligerex, feature = 'nUMI')
#' }

plotFeature <- function(object, feature, dr.method = "tsne", by.dataset = T, discrete = NULL,
                        title = NULL, pt.size = 0.3, text.size = 3, do.shuffle = T, rand.seed = 1,
                        do.labels = F, axis.labels = NULL, do.legend = T, legend.size = 5,
                        option = 'plasma', zero.color = '#F5F5F5', return.plots = F) {
  dr_df <- data.frame(object@dr.coords[[dr.method]])
  colnames(dr_df) <- c("dr1", "dr2")
  if (!(feature %in% colnames(object@cell.data))) {
    stop('Please select existing feature in cell.data, or add it before calling.')
  }
  dr_df$feature <- object@cell.data[, feature]
  if (is.null(discrete)) {
    if (class(dr_df$feature) != "factor") {
      discrete <- FALSE
    } else {
      discrete <- TRUE
    }
  }
  if (!discrete){
    dr_df$feature[dr_df$feature == 0] <- NA
  }
  if (by.dataset) {
    dr_df$dataset <- object@cell.data$dataset
  } else {
    dr_df$dataset <- factor("single")
  }
  if (do.shuffle) {
    set.seed(rand.seed)
    idx <- sample(1:nrow(dr_df))
    dr_df <- dr_df[idx, ]
  }
  p_list <- list()
  for (sub_df in split(dr_df, f = dr_df$dataset)) {
    ggp <- ggplot(sub_df, aes(x = dr1, y = dr2, color = feature)) + geom_point(size = pt.size)

    # if data is not discrete
    if (discrete) {
      ggp <- ggp + guides(color = guide_legend(override.aes = list(size = legend.size))) +
        labs(col = feature)
      if (do.labels) {
        centers <- sub_df %>% group_by(feature) %>% summarize(
          dr1 = median(x = dr1),
          dr2 = median(x = dr2)
        )
        ggp <- ggp + geom_text(data = centers, mapping = aes(label = feature),
                               colour = "black", size = text.size)
      }
    } else {
      ggp <- ggp + scale_color_viridis_c(option = option,
                                         direction = -1,
                                         na.value = zero.color) + labs(col = feature)
    }

    if (by.dataset) {
      base <- as.character(sub_df$dataset[1])
    } else {
      base <- ""
    }
    if (!is.null(title)) {
      base <- paste(title, base)
    }
    ggp <- ggp + ggtitle(base)
    if (!is.null(axis.labels)) {
      ggp <- ggp + xlab(axis.labels[1]) + ylab(axis.labels[2])
    }
    if (!do.legend) {
      ggp <- ggp + theme(legend.position = "none")
    }
    p_list[[as.character(sub_df$dataset[1])]] <- ggp
  }
  if (by.dataset) {
    p_list <- p_list[names(object@raw.data)]
  }
  
  if (return.plots){
    if (length(p_list) == 1) {
      return(p_list[[1]])
    } else {
      return(p_list)
    }
  } else {
    for (plot in p_list) {
      print(plot)
    }
  }
}

#' Plot scatter plots of unaligned and aligned factor loadings
#'
#' @description
#' Generates scatter plots of factor loadings vs cells for both unaligned and aligned
#' (normalized) factor loadings. This allows for easier visualization of the changes made to the
#' factor loadings during the alignment step. Lists a subset of highly loading genes for each factor.
#' Also provides an option to plot t-SNE coordinates of the cells colored by aligned factor loadings.
#'
#' It is recommended to call this function into a PDF due to the large number of
#' plots produced.
#'
#' @param object \code{liger} object. Should call quantileAlignSNF before calling.
#' @param num.genes Number of genes to display for each factor (default 10).
#' @param cells.highlight Names of specific cells to highlight in plot (black) (default NULL).
#' @param plot.tsne Plot t-SNE coordinates for each factor (default FALSE).
#' @param dr.method Dimensionality reduction method to reference. Should call the appropriate function
#'   (runTSNE for "tsne") or (runUMAP for "umap") first.
#'
#' @return Plots to console (1-2 pages per factor)
#' @export
#' @examples
#' \dontrun{
#'  # liger object with factorization complete
#' ligerex
#' ligerex <- quantileAlignSNF(ligerex)
#' # get tsne.coords for normalized data
#' ligerex <- runTSNE(ligerex)
#' # factor plots into pdf file
#' pdf("plot_factors.pdf")
#' plotFactors(ligerex)
#' dev.off()
#' }

plotFactors <- function(object, num.genes = 10, cells.highlight = NULL, plot.tsne = F,
                        dr.method = "tsne") {
  k <- ncol(object@H.norm)
  pb <- txtProgressBar(min = 0, max = k, style = 3)

  W <- t(object@W)
  rownames(W) <- colnames(object@scale.data[[1]])
  Hs_norm <- object@H.norm
  for (i in 1:k) {
    par(mfrow = c(2, 1))
    top_genes.W <- rownames(W)[order(W[, i], decreasing = T)[1:num.genes]]
    top_genes.W.string <- paste0(top_genes.W, collapse = ", ")
    factor_textstring <- paste0("Factor", i)

    plot_title1 <- paste(factor_textstring, "\n", top_genes.W.string, "\n")
    cols <- rep("gray", times = nrow(Hs_norm))
    names(cols) <- rownames(Hs_norm)
    cols.use <- rainbow(length(object@H))

    for (cl in 1:length(object@H)) {
      cols[rownames(object@H[[cl]])] <- rep(cols.use[cl], times = nrow(object@H[[cl]]))
    }
    if (!is.null(cells.highlight)) {
      cols[cells.highlight] <- rep("black", times = length(cells.highlight))
    }
    plot(1:nrow(Hs_norm), do.call(rbind, object@H)[, i],
         cex = 0.2, pch = 20,
         col = cols, main = plot_title1, xlab = "Cell", ylab = "Raw H Score"
    )
    legend("top", names(object@H), pch = 20, col = cols.use, horiz = T, cex = 0.75)
    plot(1:nrow(Hs_norm), object@H.norm[, i],
         pch = 20, cex = 0.2,
         col = cols, xlab = "Cell", ylab = "H_norm Score"
    )
    if (plot.tsne) {
      par(mfrow = c(1, 1))
      fplot(object@dr.coords[[dr.method]], object@H.norm[, i], title = paste0("Factor ", i))
    }
    setTxtProgressBar(pb, i)
  }
}

#' Generate word clouds and t-SNE plots
#'
#' @description
#' Plots t-SNE coordinates of all cells by their loadings on each factor. Underneath it displays the
#' most highly loading shared and dataset-specific genes, with the size of the marker indicating
#' the magnitude of the loading.
#'
#' It is recommended to call this function into a PDF due to the large number of
#' plots produced.
#'
#' @param object \code{liger} object. Should call runTSNE before calling.
#' @param dataset1 Name of first dataset (by default takes first two datasets for dataset1 and 2)
#' @param dataset2 Name of second dataset
#' @param dr.method Dimensionality reduction method to reference Should call the appropriate function
#'   (runTSNE for "tsne") or (runUMAP for "umap") first.
#' @param num.genes Number of genes to show in word clouds (default 30).
#' @param min.size Size of smallest gene symbol in word cloud (default 1).
#' @param max.size Size of largest gene symbol in word cloud (default 4).
#' @param factor.share.thresh Use only factors with a dataset specificity less than or equalt to
#'   threshold (default 10).
#' @param dataset.specificity Pre-calculated dataset specificity if available. Will calculate if not
#'   available.
#' @param log.fc.thresh Lower log-fold change threshold for differential expression in markers
#'   (default 1).
#' @param umi.thresh Lower UMI threshold for markers (default 30).
#' @param frac.thresh Lower threshold for fraction of cells expressing marker (default 0).
#' @param pval.thresh Upper p-value threshold for Wilcoxon rank test for gene expression
#'   (default 0.05).
#' @param do.spec.plot Include dataset specificity plot in printout (default TRUE).
#' @param return.plots Return ggplot objects instead of printing directly (default FALSE).
#'
#' @importFrom ggrepel geom_text_repel
#' @importFrom ggplot2 ggplot aes aes_string geom_point ggtitle scale_color_gradient scale_size
#' scale_x_continuous scale_y_continuous coord_fixed labs
#' @importFrom grid roundrectGrob
#' @importFrom grid gpar
#' @export
#' @examples
#' \dontrun{
#' # liger object, factorization complete
#' ligerex
#' ligerex <- quantileAlignSNF(ligerex)
#' ligerex <- runTSNE(ligerex)
#' pdf('word_clouds.pdf')
#' plotWordClouds(ligerex, num.genes = 20)
#' dev.off()
#' }

plotWordClouds <- function(object, dataset1 = NULL, dataset2 = NULL, num.genes = 30,
                           dr.method = "tsne", min.size = 1, max.size = 4, factor.share.thresh = 10,
                           log.fc.thresh = 1, umi.thresh = 30, frac.thresh = 0, pval.thresh = 0.05,
                           do.spec.plot = T, return.plots = F) {
  if (is.null(dataset1) | is.null(dataset2)) {
    dataset1 <- names(object@H)[1]
    dataset2 <- names(object@H)[2]
  }

  H_aligned <- object@H.norm
  W <- t(object@W)
  V1 <- t(object@V[[dataset1]])
  V2 <- t(object@V[[dataset2]])
  W <- pmin(W + V1, W + V2)

  dataset.specificity <- calcDatasetSpecificity(object, dataset1 = dataset1,
                                                dataset2 = dataset2, do.plot = do.spec.plot)
  factors.use <- which(abs(dataset.specificity[[3]]) <= factor.share.thresh)

  markers <- getFactorMarkers(object, dataset1 = dataset1, dataset2 = dataset2,
                              factor.share.thresh = factor.share.thresh,
                              num.genes = num.genes, log.fc.thresh = log.fc.thresh,
                              umi.thresh = umi.thresh, frac.thresh = frac.thresh,
                              pval.thresh = pval.thresh,
                              dataset.specificity = dataset.specificity
  )

  rownames(W) <- rownames(V1) <- rownames(V2) <- object@var.genes
  loadings_list <- list(V1, W, V2)
  names_list <- list(dataset1, "Shared", dataset2)
  tsne_coords <- object@dr.coords[[dr.method]]
  pb <- txtProgressBar(min = 0, max = length(factors.use), style = 3)
  return_plots <- list()
  for (i in factors.use) {
    tsne_df <- data.frame(H_aligned[, i], tsne_coords)
    factorlab <- paste("Factor", i, sep = "")
    colnames(tsne_df) <- c(factorlab, "tSNE1", "tSNE2")
    factor_ds <- paste("Factor", i, "Dataset Specificity:", dataset.specificity[[3]][i])
    p1 <- ggplot(tsne_df, aes_string(x = "tSNE1", y = "tSNE2", color = factorlab)) + geom_point() +
      scale_color_gradient(low = "yellow", high = "red") + ggtitle(label = factor_ds)

    top_genes_V1 <- markers[[1]]$gene[markers[[1]]$factor_num == i]
    top_genes_W <- markers[[2]]$gene[markers[[2]]$factor_num == i]
    top_genes_V2 <- markers[[3]]$gene[markers[[3]]$factor_num == i]

    top_genes_list <- list(top_genes_V1, top_genes_W, top_genes_V2)
    plot_list <- lapply(seq_along(top_genes_list), function(x) {
      top_genes <- top_genes_list[[x]]
      gene_df <- data.frame(
        genes = top_genes,
        loadings = loadings_list[[x]][top_genes, i]
      )
      if (length(top_genes) == 0) {
        gene_df <- data.frame(genes = c("no genes"), loadings = c(1))
      }
      out_plot <- ggplot(gene_df, aes(x = 1, y = 1, size = loadings, label = genes)) +
        geom_text_repel(force = 100, segment.color = NA) +
        scale_size(range = c(min.size, max.size), guide = FALSE) +
        scale_y_continuous(breaks = NULL) +
        scale_x_continuous(breaks = NULL) +
        labs(x = "", y = "") + ggtitle(label = names_list[[x]]) + coord_fixed()
      return(out_plot)
    })

    p2 <- (plot_grid(plotlist = plot_list, align = "hv", nrow = 1)
           + draw_grob(roundrectGrob(
             x = 0.33, y = 0.5, width = 0.67, height = 0.70,
             gp = gpar(fill = "khaki1", col = "Black", alpha = 0.5, lwd = 2)
           ))
           + draw_grob(roundrectGrob(
             x = 0.67, y = 0.5, width = 0.67, height = 0.70,
             gp = gpar(fill = "indianred1", col = "Black", alpha = 0.5, lwd = 2)
           )))
    return_plots[[i]] <- plot_grid(p1, p2, nrow = 2, align = "h")
    if (!return.plots) {
      print(return_plots[[i]])
    }
    setTxtProgressBar(pb, i)
  }
  if (return.plots) {
    return(return_plots)
  }
}

#' Generate t-SNE plots and gene loading plots
#'
#' @description
#' Plots t-SNE coordinates of all cells by their loadings on each factor. Underneath it displays the
#' most highly loading shared and dataset-specific genes, along with the overall gene loadings
#' for each dataset.
#'
#' It is recommended to call this function into a PDF due to the large number of
#' plots produced.
#'
#' @param object \code{liger} object. Should call runTSNE before calling.
#' @param dataset1 Name of first dataset (by default takes first two datasets for dataset1 and 2)
#' @param dataset2 Name of second dataset
#' @param dr.method Dimensionality reduction method to reference Should call the appropriate function
#'   (runTSNE for "tsne") or (runUMAP for "umap") first.
#' @param num.genes Number of genes to show in word clouds (default 30).
#' @param mark.top.genes Plot points corresponding to top loading genes in different color (default
#'   TRUE).
#' @param factor.share.thresh Use only factors with a dataset specificity less than or equal to
#'   threshold (default 10).
#' @param log.fc.thresh Lower log-fold change threshold for differential expression in markers
#'   (default 1).
#' @param umi.thresh Lower UMI threshold for markers (default 30).
#' @param frac.thresh Lower threshold for fraction of cells expressing marker (default 0).
#' @param pval.thresh Upper p-value threshold for Wilcoxon rank test for gene expression
#'   (default 0.05).
#' @param do.spec.plot Include dataset specificity plot in printout (default TRUE).
#' @param max.val Value between 0 and 1 at which color gradient should saturate to max color. Set to
#'   NULL to revert to default gradient scaling. (default 0.1)
#' @inheritParams plotGene
#' @param return.plots Return ggplot objects instead of printing directly (default FALSE).
#'
#' @importFrom ggplot2 aes aes_string annotate coord_cartesian element_blank ggplot geom_point 
#' ggtitle scale_color_viridis_c theme 
#' theme_bw
#' @importFrom grid gpar unit
#' @export
#' @examples
#' \dontrun{
#' # liger object, factorization complete
#' ligerex
#' ligerex <- quantileAlignSNF(ligerex)
#' ligerex <- runTSNE(ligerex)
#' pdf('gene_loadings.pdf')
#' plotGeneLoadings(ligerex, num.genes = 20)
#' dev.off()
#' }

plotGeneLoadings <- function(object, dataset1 = NULL, dataset2 = NULL, dr.method = "tsne",
                             num.genes.show = 12,num.genes = 30, mark.top.genes = T,
                             factor.share.thresh = 10, log.fc.thresh = 1, umi.thresh = 30,
                             frac.thresh = 0, pval.thresh = 0.05, do.spec.plot = T, max.val = 0.1,
                             pt.size = 0.1, option = "plasma", zero.color = "#F5F5F5",
                             return.plots = F) {
  if (is.null(dataset1) | is.null(dataset2)) {
    dataset1 <- names(object@H)[1]
    dataset2 <- names(object@H)[2]
  }

  H_aligned <- object@H.norm
  W_orig <- t(object@W)
  V1 <- t(object@V[[dataset1]])
  V2 <- t(object@V[[dataset2]])
  W <- pmin(W_orig + V1, W_orig + V2)

  dataset.specificity <- calcDatasetSpecificity(object,
                                                dataset1 = dataset1,
                                                dataset2 = dataset2, do.plot = do.spec.plot
  )

  factors.use <- which(abs(dataset.specificity[[3]]) <= factor.share.thresh)


  markers <- getFactorMarkers(object,
                              dataset1 = dataset1, dataset2 = dataset2,
                              factor.share.thresh = factor.share.thresh,
                              num.genes = num.genes, log.fc.thresh = log.fc.thresh,
                              umi.thresh = umi.thresh, frac.thresh = frac.thresh,
                              pval.thresh = pval.thresh,
                              dataset.specificity = dataset.specificity
  )

  rownames(W) <- rownames(V1) <- rownames(V2) <- rownames(W_orig) <- object@var.genes
  loadings_list <- list(V1, W, V2)
  names_list <- list(dataset1, "Shared", dataset2)
  tsne_coords <- object@dr.coords[[dr.method]]
  pb <- txtProgressBar(min = 0, max = length(factors.use), style = 3)
  return_plots <- list()
  for (i in factors.use) {
    tsne_df <- data.frame(H_aligned[, i], tsne_coords)
    factorlab <- paste("Factor", i, sep = "")
    colnames(tsne_df) <- c(factorlab, "tSNE1", "tSNE2")
    tsne_df[[factorlab]][tsne_df[[factorlab]] == 0] <- NA
    factor_ds <- paste("Factor", i, "Dataset Specificity:", dataset.specificity[[3]][i])
    data.max <- max(object@H.norm[, i])
    # plot TSNE
    if (!is.null(max.val)) {
      values <- c(0, max.val, 1)
    } else {
      values <- NULL
    }
    p1 <- ggplot(tsne_df, aes_string(x = "tSNE1", y = "tSNE2", color = factorlab)) +
      geom_point(size = pt.size) +
      scale_color_viridis_c(
        option = option,
        direction = -1,
        na.value = zero.color, values = values
      ) +
      ggtitle(label = factor_ds)

    # subset to specific factor and sort by p-value
    top_genes_V1 <- markers[[1]][markers[[1]]$factor_num == i, ]
    top_genes_V1 <- top_genes_V1[order(top_genes_V1$p_value), ]$gene
    # don't sort for W
    top_genes_W <- markers[[2]][markers[[2]]$factor_num == i, ]$gene
    top_genes_V2 <- markers[[3]][markers[[3]]$factor_num == i, ]
    top_genes_V2 <- top_genes_V2[order(top_genes_V2$p_value), ]$gene

    top_genes_list <- list(top_genes_V1, top_genes_W, top_genes_V2)
    # subset down to those which will be shown if sorting by p-val

    top_genes_list <- lapply(top_genes_list, function(x) {
      if (length(x) > num.genes.show) {
        # to avoid subset warning
        x <- x[1:num.genes.show]
      }
      x
    })

    plot_list <- lapply(seq_along(top_genes_list), function(x) {
      top_genes <- top_genes_list[[x]]
      # make dataframe for cum gene loadings plot
      sorted <- sort(loadings_list[[x]][, i])
      # sort by loadings instead - still only showing num.genes.show
      # look through top num.genes in loadings
      top_loaded <- names(rev(sorted[(length(sorted) - num.genes + 1):length(sorted)]))
      top_genes <- top_loaded[which(top_loaded %in% top_genes)]
      if (length(top_genes) == 0) {
        top_genes <- c("no genes")
      }

      gene_df <- data.frame(
        loadings = sorted,
        xpos = seq(0, 1, length.out = length(sorted)),
        top_k = names(sorted) %in% top_genes
      )
      y_lim_text <- max(gene_df$loadings)
      # plot and annotate with top genes
      out_plot <- ggplot(gene_df, aes(x = xpos, y = loadings)) + geom_point(size = 0.4) +
        theme_bw() +
        theme(
          axis.ticks.x = element_blank(),
          axis.line.x = element_blank(),
          axis.title = element_blank(),
          axis.text.x = element_blank(),
          panel.grid.major.x = element_blank(),
          panel.grid.minor.x = element_blank()
        ) + ggtitle(label = names_list[[x]]) +
        annotate("text",
                 x = 1.1,
                 y = seq(y_lim_text, 0, length.out = num.genes.show)[1:length(top_genes)],
                 label = top_genes, hjust = 0, col = "#8227A0"
        ) +
        coord_cartesian(
          xlim = c(0, 1), # This focuses the x-axis on the range of interest
          clip = "off"
        ) +
        theme(plot.margin = unit(c(1, 4, 1, 1), "lines"))
      if (mark.top.genes) {
        out_plot <- out_plot + geom_point(
          data = subset(gene_df, top_k == TRUE),
          aes(xpos, loadings),
          col = "#8227A0", size = 0.5
        )
      }
      return(out_plot)
    })

    # p2 <- plot_grid(plotlist = plot_list, nrow = 1)

    return_plots[[i]] <- p1 / (plot_list[[1]] | plot_list[[2]] | plot_list[[3]])
    # if can figure out how to make cowplot work, might bring this back
    # return_plots[[i]] <- plot_grid(p1, p2, nrow = 2, align = "h")
    if (!return.plots) {
      print(return_plots[[i]])
    }
    setTxtProgressBar(pb, i)
  }
  if (return.plots) {
    return(return_plots)
  }
}

#' Plot violin plots for gene expression
#'
#' Generates violin plots of expression of specified gene for each dataset.
#'
#' @param object \code{liger} object.
#' @param gene Gene for which to plot relative expression.
#' @param methylation.indices Indices of datasets in object with methylation data (this data is not
#'   magnified and put on log scale).
#' @param dr.method Dimensionality reduction method to reference Should call the appropriate function
#'   (runTSNE for "tsne") or (runUMAP for "umap") first.
#' @param by.dataset Plots gene expression for each dataset separately (default TRUE).
#' @param return.plots Return ggplot objects instead of printing directly to console (default
#'   FALSE).
#'
#' @export
#' @importFrom cowplot plot_grid
#' @importFrom ggplot2 aes_string ggplot geom_point geom_boxplot geom_violin ggtitle labs
#' scale_color_gradient2 theme 
#' @examples
#' \dontrun{
#' # liger object, factorization complete
#' ligerex
#' # plot expression for CD4 and return plots
#' violin_plots <- plotGeneViolin(ligerex, "CD4", return.plots = T)
#' }

plotGeneViolin <- function(object, gene, methylation.indices = NULL, dr.method = "tsne",
                           by.dataset = T, return.plots = F) {
  gene_vals <- c()
  for (i in 1:length(object@norm.data)) {
    if (i %in% methylation.indices) {
      gene_vals <- c(gene_vals, object@norm.data[[i]][gene, ])
    } else {
      if (gene %in% rownames(object@norm.data[[i]])) {
        gene_vals_int <- log2(10000 * object@norm.data[[i]][gene, ] + 1)
      }
      else {
        gene_vals_int <- rep(list(0), ncol(object@norm.data[[i]]))
        names(gene_vals_int) <- colnames(object@norm.data[[i]])
      }
      gene_vals <- c(gene_vals, gene_vals_int)
    }
  }

  gene_df <- data.frame(object@dr.coords[[dr.method]])
  rownames(gene_df) <- names(object@clusters)
  gene_df$Gene <- as.numeric(gene_vals[rownames(gene_df)])
  colnames(gene_df) <- c("tSNE1", "tSNE2", "gene")
  gene_plots <- list()
  for (i in 1:length(object@scale.data)) {
    if (by.dataset) {
      gene_df.sub <- gene_df[rownames(object@scale.data[[i]]), ]
      gene_df.sub$Cluster <- object@clusters[rownames(object@scale.data[[i]])]
      title <- names(object@scale.data)[i]
    } else {
      gene_df.sub <- gene_df
      gene_df.sub$Cluster <- object@clusters
      title <- "All Datasets"
    }
    max_v <- max(gene_df.sub["gene"], na.rm = T)
    min_v <- min(gene_df.sub["gene"], na.rm = T)
    midpoint <- (max_v - min_v) / 2
    plot_i <- ggplot(gene_df.sub, aes_string(x = "Cluster", y = "gene", fill = "Cluster")) +
                 geom_boxplot(position = "dodge", width = 0.4, outlier.shape = NA, alpha = 0.7) +
                 geom_violin(position = "dodge", alpha = 0.7) +
                 ggtitle(title)
    gene_plots[[i]] <- plot_i + theme(legend.position = "none") + labs(y = gene)
    if (i == 1 & !by.dataset) {
      break
    }
  }
  if (return.plots) {
    return(gene_plots)
  } else {
    for (i in 1:length(gene_plots)) {
      print(gene_plots[[i]])
    }
  }
}

#' Plot t-SNE coordinates by expression of specified gene
#'
#' Generates plot of t-SNE coordinates colored by expression of specified gene, for each dataset.
#' Color scale can be modified.
#'
#' @param object \code{liger} object. Should call runTSNE before calling.
#' @param gene Gene for which to plot relative expression.
#' @param use.raw Plot raw values instead of normalized and log-transformed data (default FALSE).
#' @param methylation.indices Indices of datasets in object with methylation data (this data is not
#'   magnified and put on log scale).
#' @param pt.size Point size for plots (default 0.1)
#' @param min.clip Quantile probability for lower bound of methylation data (everything lower set
#'   to this quantile value) (default 0)
#' @param max.clip Quantile probability for upper bound of methylation data (everything greater set
#'   to this quantile value) (default 1)
#' @param points.only Remove axes when plotting t-sne coordinates (default FALSE).
#' @param option Colormap option to use for ggplot2's scale_color_viridis (default 'plasma').
#' @param zero.color Color to use for zero values (no expression) (default '#F5F5F5').
#' @param return.plots Return ggplot objects instead of printing directly (default FALSE).
#'
#' @export
#' @importFrom ggplot2 ggplot geom_point aes_string element_blank ggtitle labs 
#' scale_color_viridis_c theme
#' @examples
#' \dontrun
#' # liger object, factorization complete
#' ligerex
#' ligerex <- runTSNE(ligerex)
#' # plot expression for CD4 and return plots
#' gene_plots <- plotGene(ligerex, "CD4", return.plots = T)
#' }

plotGene <- function(object, gene, use.raw = F, methylation.indices = NULL, pt.size = 0.1,
                     min.clip = 0, max.clip = 1, points.only = F, option = 'plasma',
                     zero.color = '#F5F5F5', return.plots = F) {
  gene_vals <- c()
  if (use.raw) {
    for (i in 1:length(object@raw.data)) {
      if (gene %in% rownames(object@raw.data[[i]])) {
        gene_vals_int <- object@raw.data[[i]][gene, ]
      } else {
        gene_vals_int <- rep(list(NA), ncol(object@raw.data[[i]]))
        names(gene_vals_int) <- colnames(object@raw.data[[i]])
      }
      gene_vals <- c(gene_vals, gene_vals_int)
    }
  } else {
    for (i in 1:length(object@norm.data)) {
      if (i %in% methylation.indices) {
        tmp <- object@norm.data[[i]][gene, ]
        max_v <- quantile(tmp, probs = max.clip, na.rm = T)
        min_v <- quantile(tmp, probs = min.clip, na.rm = T)
        tmp[tmp < min_v & !is.na(tmp)] <- min_v
        tmp[tmp > max_v & !is.na(tmp)] <- max_v
        gene_vals <- c(gene_vals, tmp)
      } else {
        if (gene %in% rownames(object@norm.data[[i]])) {
          gene_vals_int <- log2(10000 * object@norm.data[[i]][gene, ] + 1)
        } else {
          gene_vals_int <- rep(list(NA), ncol(object@norm.data[[i]]))
          names(gene_vals_int) <- colnames(object@norm.data[[i]])
        }
        gene_vals <- c(gene_vals, gene_vals_int)
      }
    }
  }
  gene_vals[gene_vals == 0] <- NA
  gene_df <- data.frame(object@dr.coords[["tsne"]])
  rownames(gene_df) <- names(object@clusters)
  gene_df$Gene <- as.numeric(gene_vals[rownames(gene_df)])
  colnames(gene_df) <- c("tSNE1", "tSNE2", "gene")
  gene_plots <- list()
  for (i in 1:length(object@norm.data)) {
    gene_df.sub <- gene_df[rownames(object@scale.data[[i]]), ]
    plot_i <- (ggplot(gene_df.sub, aes_string(x = "tSNE1", y = "tSNE2", color = "gene")) +
                 geom_point(size = pt.size) +
                 scale_color_viridis_c(option = option,
                                       direction = -1,
                                       na.value = zero.color) +
                 labs(col = gene) +
                 ggtitle(names(object@scale.data)[i]))
    gene_plots[[i]] <- plot_i
  }
  if (points.only) {
    for (i in 1:length(gene_plots)) {
      gene_plots[[i]] <- gene_plots[[i]] + theme(
        axis.line = element_blank(), axis.text.x = element_blank(),
        axis.text.y = element_blank(), axis.ticks = element_blank(),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(), legend.position = "none",
        panel.background = element_blank(), panel.border = element_blank(),
        panel.grid.major = element_blank(), panel.grid.minor = element_blank(),
        plot.background = element_blank(), plot.title = element_blank()
      )
    }
  }
  if (return.plots) {
    return(gene_plots)
  } else {
    for (i in 1:length(gene_plots)) {
      print(gene_plots[[i]])
    }
  }
}

#' Plot expression of multiple genes
#'
#' Uses plotGene to plot each gene (and dataset) on a separate page. It is recommended to call this
#' function into a PDF due to the large number of plots produced.
#'
#' @param object \code{liger} object. Should call runTSNE before calling.
#' @param genes Vector of gene names.
#'
#' @export
#' @importFrom ggplot2 ggplot geom_point aes_string scale_color_gradient2 ggtitle
#' @examples
#' \dontrun{
#' # liger object, factorization complete
#' ligerex
#' ligerex <- runTSNE(ligerex)
#' # plot expression for CD4 and FCGR3A
#' pdf("gene_plots.pdf")
#' plotGenes(ligerex, c("CD4", "FCGR3A"))
#' dev.off()
#' }

plotGenes <- function(object, genes) {
  for (i in 1:length(genes)) {
    print(genes[i])
    plotGene(object, genes[i])
  }
}

#' Generate a river (Sankey) plot
#'
#' Creates a riverplot to show how separate cluster assignments from two datasets map onto a
#' joint clustering. The joint clustering is by default the object clustering, but an external one
#' can also be passed in. Uses the riverplot package to construct riverplot object and then plot.
#'
#' @param object \code{liger} object. Should run quantileAlignSNF before calling.
#' @param cluster1 Cluster assignments for dataset 1. Note that cluster names should be distinct
#'   across datasets.
#' @param cluster2 Cluster assignments for dataset 2. Note that cluster names should be distinct
#'   across datasets.
#' @param cluster_consensus Optional external consensus clustering (to use instead of object
#'   clusters)
#' @param min.frac Minimum fraction of cluster for edge to be shown (default 0.05).
#' @param min.cells Minumum number of cells for edge to be shown (default 10).
#' @param river.yscale y-scale to pass to riverplot -- scales the edge with values by this factor,
#'   can be used to squeeze vertically (default 1).
#' @param river.lty Line style to pass to riverplot (default 0).
#' @param river.node_margin Node_margin to pass to riverplot -- how much vertical space to keep
#'   between the nodes (default 0.1).
#' @param label.cex Size of text labels (default 1).
#' @param label.col Color of text labels (defualt "black").
#' @param lab.srt Angle of text labels (default 0).
#' @param river.usr Coordinates at which to draw the plot in form (x0, x1, y0, y1).
#' @param node.order Order of clusters in each set (list with three vectors of ordinal numbers).
#'   By default will try to automatically order them appropriately.
#'
#' @export
#' @importFrom plyr mapvalues
#' @importFrom riverplot makeRiver
# @importFrom riverplot plot.riverplot
#' @examples
#' \dontrun{
#' # liger object, factorization done
#' ligerex
#' ligerex <- quantileAlignSNF(ligerex)
#' # toy clusters
#' cluster1 <- sample(c('type1', 'type2', 'type3'), ncol(ligerex@raw.data[[1]]), replace = T)
#' names(cluster1) <- colnames(ligerex@raw.data[[1]])
#' cluster2 <- sample(c('type4', 'type5', 'type6'), ncol(ligerex@raw.data[[2]]), replace = T)
#' names(cluster2) <- colnames(ligerex@raw.data[[2]])
#' # create riverplot
#' makeRiverplot(ligerex, cluster1, cluster2)
#' }

makeRiverplot <- function(object, cluster1, cluster2, cluster_consensus = NULL, min.frac = 0.05,
                          min.cells = 10, river.yscale = 1, river.lty = 0, river.node_margin = 0.1,
                          label.cex = 1, label.col = "black", lab.srt = 0, river.usr = NULL,
                          node.order = "auto") {
  cluster1 <- droplevels(cluster1)
  cluster2 <- droplevels(cluster2)
  if (is.null(cluster_consensus)) {
    cluster_consensus <- droplevels(object@clusters)
  }
  # Make cluster names unique if necessary
  if (length(intersect(levels(cluster1), levels(cluster2))) > 0 |
      length(intersect(levels(cluster1), levels(cluster_consensus))) > 0 |
      length(intersect(levels(cluster2), levels(cluster_consensus))) > 0) {
    print("Duplicate cluster names detected. Adding 1- and 2- to make unique names.")
    cluster1 <- mapvalues(cluster1, from = levels(cluster1),
                          to = paste("1", levels(cluster1), sep = "-"))
    cluster2 <- mapvalues(cluster2, from = levels(cluster2),
                          to = paste("2", levels(cluster2), sep = "-"))
  }
  # set node order
  if (identical(node.order, "auto")) {
    tab.1 <- table(cluster1, cluster_consensus[names(cluster1)])
    tab.1 <- sweep(tab.1, 1, rowSums(tab.1), "/")
    tab.2 <- table(cluster2, cluster_consensus[names(cluster2)])
    tab.2 <- sweep(tab.2, 1, rowSums(tab.2), "/")
    whichmax.1 <- apply(tab.1, 1, which.max)
    whichmax.2 <- apply(tab.2, 1, which.max)
    ord.1 <- order(whichmax.1)
    ord.2 <- order(whichmax.2)
    cluster1 <- factor(cluster1, levels = levels(cluster1)[ord.1])
    cluster2 <- factor(cluster2, levels = levels(cluster2)[ord.2])
  } else {
    if (is.list(node.order)) {
      cluster1 <- factor(cluster1, levels = levels(cluster1)[node.order[[1]]])
      cluster_consensus <- factor(cluster_consensus,
                                  levels = levels(cluster_consensus)[node.order[[2]]])
      cluster2 <- factor(cluster2, levels = levels(cluster2)[node.order[[3]]])
    }
  }
  cluster1 <- cluster1[!is.na(cluster1)]
  cluster2 <- cluster2[!is.na(cluster2)]
  nodes1 <- levels(cluster1)[table(cluster1) > 0]
  nodes2 <- levels(cluster2)[table(cluster2) > 0]
  nodes_middle <- levels(cluster_consensus)[table(cluster_consensus) > 0]
  node_Xs <- c(
    rep(1, length(nodes1)), rep(2, length(nodes_middle)),
    rep(3, length(nodes2))
  )

  # first set of edges
  edge_list <- list()
  for (i in 1:length(nodes1)) {
    temp <- list()
    i_cells <- names(cluster1)[cluster1 == nodes1[i]]
    for (j in 1:length(nodes_middle)) {
      if (length(which(cluster_consensus[i_cells] == nodes_middle[j])) / length(i_cells) > min.frac &
          length(which(cluster_consensus[i_cells] == nodes_middle[j])) > min.cells) {
        temp[[nodes_middle[j]]] <- sum(cluster_consensus[i_cells] ==
                                         nodes_middle[j]) / length(cluster1)
      }
    }
    edge_list[[nodes1[i]]] <- temp
  }
  # second set of edges
  cluster3 <- cluster_consensus[names(cluster2)]
  for (i in 1:length(nodes_middle)) {
    temp <- list()
    i_cells <- names(cluster3)[cluster3 == nodes_middle[i]]
    for (j in 1:length(nodes2)) {
      j_cells <- names(cluster2)[cluster2 == nodes2[j]]
      if (length(which(cluster_consensus[j_cells] == nodes_middle[i])) / length(j_cells) > min.frac &
          length(which(cluster_consensus[j_cells] == nodes_middle[i])) > min.cells) {
        if (!is.na(sum(cluster2[i_cells] == nodes2[j]))) {
          temp[[nodes2[j]]] <- sum(cluster2[i_cells] ==
                                     nodes2[j]) / length(cluster2)
        }
      }
    }
    edge_list[[nodes_middle[i]]] <- temp
  }
  # set cluster colors
  node_cols <- list()
  ggplotColors <- function(g) {
    d <- 360 / g
    h <- cumsum(c(15, rep(d, g - 1)))
    hcl(h = h, c = 100, l = 65)
  }
  pal <- ggplotColors(length(nodes1))
  for (i in 1:length(nodes1)) {
    node_cols[[nodes1[i]]] <- list(col = pal[i], textcex = label.cex,
                                   textcol = label.col, srt = lab.srt)
  }
  pal <- ggplotColors(length(nodes_middle))
  for (i in 1:length(nodes_middle)) {
    node_cols[[nodes_middle[i]]] <- list(col = pal[i], textcex = label.cex,
                                         textcol = label.col, srt = lab.srt)
  }
  pal <- ggplotColors(length(nodes2))
  for (i in 1:length(nodes2)) {
    node_cols[[nodes2[i]]] <- list(col = pal[i], textcex = label.cex,
                                   textcol = label.col, srt = lab.srt)
  }
  # create nodes and riverplot object
  nodes <- list(nodes1, nodes_middle, nodes2)
  node.limit <- max(unlist(lapply(nodes, length)))

  node_Ys <- lapply(1:length(nodes), function(i) {
    seq(1, node.limit, by = node.limit / length(nodes[[i]]))
  })
  rp <- makeRiver(c(nodes1, nodes_middle, nodes2), edge_list,
                  node_xpos = node_Xs, node_ypos = unlist(node_Ys), node_styles = node_cols
  )
  # prevent normal riverplot output being printed to console
  invisible(capture.output(riverplot(rp,
                                     yscale = river.yscale, lty = river.lty,
                                     node_margin = river.node_margin, usr = river.usr
  )))
}

#' Plot cluster proportions by dataset
#'
#' Generates plot of clusters sized by the proportion of total cells
#'
#' @param object \code{liger} object. Should call quantileAlignSNF before calling.
#' @param return.plot Return ggplot object (default FALSE)
#'
#' @export
#' @importFrom grid unit
#' @importFrom ggplot2 ggplot aes coord_fixed element_blank geom_point guides guide_legend 
#' scale_size scale_y_discrete theme
#' @examples
#' \dontrun{
#' # liger object, factorization complete
#' ligerex
#' ligerex <- quantileAlignSNF(ligerex)
#' # plot cluster proportions
#' plotClusterProportions(ligerex)
#' }

plotClusterProportions <- function(object, return.plot = F) {
  sample_names <- unlist(lapply(seq_along(object@scale.data), function(i) {
    rep(names(object@scale.data)[i], nrow(object@scale.data[[i]]))
  }))
  freq_table <- data.frame(Cluster = rep(object@clusters, length(object@scale.data)),
                           Sample = sample_names)
  freq_table <- table(freq_table$Cluster, freq_table$Sample)
  for (i in 1:ncol(freq_table)) {
    freq_table[, i] <- freq_table[, i] / sum(freq_table[, i])
  }
  freq_table <- data.frame(freq_table)
  colnames(freq_table) <- c("Cluster", "Sample", "Proportion")
  p1 <- ggplot(freq_table, aes(x = Cluster, y = Sample)) +
    geom_point(aes(size = Proportion, fill = Cluster, color = Cluster)) +
    scale_size(guide = "none") + theme(
      axis.line = element_blank(),
      axis.text.x = element_blank(),
      axis.title.y = element_blank(),
      axis.ticks = element_blank(),
      axis.title.x = element_blank(),
      legend.title = element_blank(),
      legend.position = 'bottom',
      plot.margin = unit(c(0, 0, 0, 0), "cm"),
      legend.justification = "center"
    ) + scale_y_discrete(position = "right") +
    guides(fill = guide_legend(ncol = 6, override.aes = list(size = 4))) +
    coord_fixed(ratio = 0.5)
  if (return.plot) {
    return(p1)
  }
  else {
    print(p1)
  }
}

#' Plot heatmap of cluster/factor correspondence
#'
#' Generates matrix of cluster/factor correspondence, using sum of row-normalized factor loadings
#' for every cell in each cluster. Plots heatmap of matrix, with red representing high total
#' loadings for a factor, black low. Optionally can also include dendrograms and sorting for
#' factors and clusters.
#'
#' @param object \code{liger} object.
#' @param use.aligned Use quantile normalized factor loadings to generate matrix (default FALSE).
#' @param Rowv Determines if and how the row dendrogram should be computed and reordered. Either a
#'   dendrogram or a vector of values used to reorder the row dendrogram or NA to suppress any row
#'   dendrogram (and reordering) (default NA for no dendrogram).
#' @param Colv Determines if and how the column dendrogram should be reordered. Has the same options
#'   as the Rowv argument (default 'Rowv' to match Rowv).
#' @param col Color map to use (defaults to red and black)
#' @param return.data Return matrix of total factor loadings for each cluster (default FALSE).
#' @param ... Additional parameters to pass on to heatmap()
#'
#' @export
#' @return If requested, matrix of size num_cluster x num_factor
#' @examples
#' \dontrun{
#' # liger object, factorization complete
#' ligerex
#' # plot expression for CD4 and return plots
#' loading.matrix <- plotClusterFactors(ligerex, return.data = T)
#' }

plotClusterFactors <- function(object, use.aligned = F, Rowv = NA, Colv = "Rowv", col = NULL,
                               return.data = F, ...) {
  if (use.aligned) {
    data.mat <- object@H.norm
  } else {
    scaled <- lapply(object@H, function(i) {
      scale(i, center = F, scale = T)
    })
    data.mat <- Reduce(rbind, scaled)
  }
  row.scaled <- t(apply(data.mat, 1, function(x) {
    x / sum(x)
  }))
  cluster.bars <- list()
  for (cluster in levels(object@clusters)) {
    cluster.bars[[cluster]] <- colSums(row.scaled[names(object@clusters)
                                                  [which(object@clusters == cluster)], ])

  }
  cluster.bars <- Reduce(rbind, cluster.bars)
  if (is.null(col)) {
    colfunc <- colorRampPalette(c("black", "red"))
    col <- colfunc(15)
  }
  rownames(cluster.bars) <- levels(object@clusters)
  colnames(cluster.bars) <- 1:ncol(cluster.bars)
  title <- ifelse(use.aligned, "H.norm", "raw H")
  heatmap(cluster.bars,
          Rowv = Rowv, Colv = Rowv, col = col, xlab = "Factor", ylab = "Cluster",
          main = title, ...
  )
  if (return.data) {
    return(cluster.bars)
  }
}

#######################################################################################
#### Marker/Cell Analysis

#' Find shared and dataset-specific markers
#'
#' Applies various filters to genes on the shared (W) and dataset-specific (V) components of the
#' factorization, before selecting those which load most significantly on each factor (in a shared
#' or dataset-specific way).
#'
#' @param object \code{liger} object. Should call optimizeALS before calling.
#' @param dataset1 Name of first dataset (default first dataset by order)
#' @param dataset2 Name of second dataset (default second dataset by order)
#' @param factor.share.thresh Use only factors with a dataset specificity less than or equalt to
#'   threshold (default 10).
#' @param dataset.specificity Pre-calculated dataset specificity if available. Will calculate if not
#'   available.
#' @param log.fc.thresh Lower log-fold change threshold for differential expression in markers
#'   (default 1).
#' @param umi.thresh Lower UMI threshold for markers (default 30).
#' @param frac.thresh Lower threshold for fraction of cells expressing marker (default 0).
#' @param pval.thresh Upper p-value threshold for Wilcoxon rank test for gene expression
#'   (default 0.05).
#' @param num.genes Max number of genes to report for each dataset (default 30).
#' @param print.genes Print ordered markers passing logfc, umi and frac thresholds (default FALSE).
#'
#' @return List of shared and specific factors. First three elements are dataframes of dataset1-
#'   specific, shared, and dataset2-specific markers. Last two elements are tables indicating the
#'   number of factors in which marker appears.
#' @export
#' @examples
#' \dontrun{
#' # liger object, factorization complete
#' ligerex
#' markers <- getFactorMarkers(ligerex, num.genes = 10)
#' # look at shared markers
#' head(markers[[2]])
#' }

getFactorMarkers <- function(object, dataset1 = NULL, dataset2 = NULL, factor.share.thresh = 10,
                             dataset.specificity = NULL, log.fc.thresh = 1, umi.thresh = 30,
                             frac.thresh = 0, pval.thresh = 0.05, num.genes = 30, print.genes = F) {
  if (is.null(dataset1) | is.null(dataset2)) {
    dataset1 <- names(object@H)[1]
    dataset2 <- names(object@H)[2]
  }
  if (is.null(num.genes)) {
    num.genes <- length(object@var.genes)
  }
  if (is.null(dataset.specificity)) {
    dataset.specificity <- calcDatasetSpecificity(object, dataset1 = dataset1,
                                                  dataset2 = dataset2, do.plot = F)
  }
  factors.use <- which(abs(dataset.specificity[[3]]) <= factor.share.thresh)

  if (length(factors.use) < 2) {
    print(paste(
      "Warning: only", length(factors.use),
      "factors passed the dataset specificity threshold."
    ))
  }

  Hs_scaled <- lapply(object@H, function(x) {
    scale(x, scale = T, center = T)
  })
  labels <- list()
  for (i in 1:length(Hs_scaled)) {
    labels[[i]] <- factors.use[as.factor(apply(Hs_scaled[[i]][, factors.use], 1, which.max))]
  }
  names(labels) <- names(object@H)

  V1_matrices <- list()
  V2_matrices <- list()
  W_matrices <- list()
  for (j in 1:length(factors.use)) {
    i <- factors.use[j]

    W <- t(object@W)
    V1 <- t(object@V[[dataset1]])
    V2 <- t(object@V[[dataset2]])
    rownames(W) <- rownames(V1) <- rownames(V2) <- object@var.genes
    # if not max factor for any cell in either dataset
    if (sum(labels[[dataset1]] == i) <= 1 | sum(labels[[dataset2]] == i) <= 1) {
      print(paste("Warning: factor", i, "did not appear as max in any cell in either dataset"))
      next
    }
    # filter genes by gene_count and cell_frac thresholds
    gene_info <- list()
    for (dset in c(dataset1, dataset2)) {
      gene_info[[dset]]$gene_counts <- rowSums(object@raw.data[[dset]][
        object@var.genes,
        labels[[dset]] == i
        ])
      gene_info[[dset]]$cell_fracs <- rowSums(object@raw.data[[dset]][object@var.genes,
                                                                      labels[[dset]] == i] > 0) /
        sum(labels[[dset]] == i)
      gene_info[[dset]]$norm_counts <- object@norm.data[[dset]][object@var.genes,
                                                                labels[[dset]] == i]
      gene_info[[dset]]$mean <- rowMeans(object@norm.data[[dset]][
        object@var.genes,
        labels[[dset]] == i
        ])
      names(gene_info[[dset]]$gene_counts) <- names(gene_info[[dset]]$mean) <- object@var.genes
      rownames(gene_info[[dset]]$norm_counts) <- object@var.genes
    }
    log2fc <- log2(gene_info[[dataset1]]$mean / gene_info[[dataset2]]$mean)
    initial_filtered <- object@var.genes[(gene_info[[dataset1]]$gene_counts > umi.thresh |
                                            gene_info[[dataset2]]$gene_counts > umi.thresh) &
                                           (gene_info[[dataset1]]$cell_fracs > frac.thresh |
                                              gene_info[[dataset2]]$cell_fracs > frac.thresh)]
    filtered_genes_V1 <- initial_filtered[log2fc[initial_filtered] > log.fc.thresh]
    filtered_genes_V2 <- initial_filtered[(-1 * log2fc)[initial_filtered] > log.fc.thresh]

    W <- pmin(W + V1, W + V2)
    V1 <- V1[filtered_genes_V1, , drop = F]
    V2 <- V2[filtered_genes_V2, , drop = F]

    if (length(filtered_genes_V1) == 0) {
      top_genes_V1 <- character(0)
    } else {
      top_genes_V1 <- row.names(V1)[ order(V1[, i], decreasing = T)[1:num.genes] ]
      top_genes_V1 <- top_genes_V1[!is.na(top_genes_V1)]
      top_genes_V1 <- top_genes_V1[which(V1[top_genes_V1, i] > 0)]
    }
    if (length(filtered_genes_V2) == 0) {
      top_genes_V2 <- character(0)
    } else {
      top_genes_V2 <- row.names(V2)[ order(V2[, i], decreasing = T)[1:num.genes] ]
      top_genes_V2 <- top_genes_V2[!is.na(top_genes_V2)]
      top_genes_V2 <- top_genes_V2[which(V2[top_genes_V2, i] > 0)]
    }
    top_genes_W <- row.names(W)[ order(W[, i], decreasing = T)[1:num.genes] ]
    top_genes_W <- top_genes_W[!is.na(top_genes_W)]
    top_genes_W <- top_genes_W[which(W[top_genes_W, i] > 0)]

    if (print.genes) {
      print(paste("Factor", i))
      print('Dataset 1')
      print(top_genes_V1)
      print('Shared')
      print(top_genes_W)
      print('Dataset 2')
      print(top_genes_V2)
    }

    pvals <- list() # order is V1, V2, W
    top_genes <- list(top_genes_V1, top_genes_V2, top_genes_W)
    for (k in 1:length(top_genes)) {
      pvals[[k]] <- sapply(top_genes[[k]], function(x) {
        suppressWarnings(wilcox.test(
          as.numeric(gene_info[[dataset1]]$norm_counts[x, ]),
          as.numeric(gene_info[[dataset2]]$norm_counts[x, ])
        )$p.value)
      })
    }
    # bind values in matrices
    V1_matrices[[j]] <- Reduce(cbind, list(
      rep(i, length(top_genes_V1)), top_genes_V1,
      gene_info[[dataset1]]$gene_counts[top_genes_V1],
      gene_info[[dataset2]]$gene_counts[top_genes_V1],
      gene_info[[dataset1]]$cell_fracs[top_genes_V1],
      gene_info[[dataset2]]$cell_fracs[top_genes_V1],
      log2fc[top_genes_V1], pvals[[1]]
    ))
    V2_matrices[[j]] <- Reduce(cbind, list(
      rep(i, length(top_genes_V2)), top_genes_V2,
      gene_info[[dataset1]]$gene_counts[top_genes_V2],
      gene_info[[dataset2]]$gene_counts[top_genes_V2],
      gene_info[[dataset1]]$cell_fracs[top_genes_V2],
      gene_info[[dataset2]]$cell_fracs[top_genes_V2],
      log2fc[top_genes_V2], pvals[[2]]
    ))
    W_matrices[[j]] <- Reduce(cbind, list(
      rep(i, length(top_genes_W)), top_genes_W,
      gene_info[[dataset1]]$gene_counts[top_genes_W],
      gene_info[[dataset2]]$gene_counts[top_genes_W],
      gene_info[[dataset1]]$cell_fracs[top_genes_W],
      gene_info[[dataset2]]$cell_fracs[top_genes_W],
      log2fc[top_genes_W], pvals[[3]]
    ))
  }
  V1_genes <- data.frame(Reduce(rbind, V1_matrices), stringsAsFactors = F)
  V2_genes <- data.frame(Reduce(rbind, V2_matrices), stringsAsFactors = F)
  W_genes <- data.frame(Reduce(rbind, W_matrices), stringsAsFactors = F)
  df_cols <- c("factor_num", "gene", "counts1", "counts2", "fracs1", "fracs2", "log2fc", "p_value")
  output_list <- list(V1_genes, W_genes, V2_genes)
  output_list <- lapply(seq_along(output_list), function(x) {
    df <- output_list[[x]]
    colnames(df) <- df_cols
    df <- transform(df,
                    factor_num = as.numeric(factor_num), gene = as.character(gene),
                    counts1 = as.numeric(counts1), counts2 = as.numeric(counts2),
                    fracs1 = as.numeric(fracs1), fracs2 = as.numeric(fracs2),
                    log2fc = as.numeric(log2fc), p_value = as.numeric(p_value)
    )
    # Cutoff only applies to dataset-specific dfs
    if (x != 2) {
      df[which(df$p_value < pval.thresh), ]
    } else {
      df
    }
  })
  names(output_list) <- c(dataset1, "shared", dataset2)
  output_list[["num_factors_V1"]] <- table(output_list[[dataset1]]$gene)
  output_list[["num_factors_V2"]] <- table(output_list[[dataset2]]$gene)
  return(output_list)
}

#######################################################################################
#### Conversion/Transformation

#' Create a Seurat object containing the data from a liger object
#'
#' Merges raw.data and scale.data of object, and creates Seurat object with these values along with
#' tsne.coords, iNMF factorization, and cluster assignments. Supports Seurat V2 and V3.
#'
#' Stores original dataset identity by default in new object metadata if dataset names are passed
#' in nms. iNMF factorization is stored in dim.reduction object with key "iNMF".
#'
#' @param object \code{liger} object.
#' @param nms By default, labels cell names with dataset of origin (this is to account for cells in
#'   different datasets which may have same name). Other names can be passed here as vector, must
#'   have same length as the number of datasets. (default names(H))
#' @param renormalize Whether to log-normalize raw data using Seurat defaults (default TRUE).
#' @param use.liger.genes Whether to carry over variable genes (default TRUE).
#' @param by.dataset Include dataset of origin in cluster identity in Seurat object (default FALSE).
#'
#' @return Seurat object with raw.data, scale.data, dr$tsne, dr$inmf, and ident slots set.
#' @export
#' @examples
#' \dontrun{
#' # liger object
#' ligerex
#' s.object <- ligerToSeurat(ligerex)
#' }

ligerToSeurat <- function(object, nms = names(object@H), renormalize = T, use.liger.genes = T,
                          by.dataset = F) {
  if (!require("Seurat", quietly = TRUE)) {
    stop("Package \"Seurat\" needed for this function to work. Please install it.",
         call. = FALSE
    )
  }
  # get Seurat version
  maj_version <- packageVersion('Seurat')$major
  if (class(object@raw.data[[1]])[1] != 'dgCMatrix') {
    mat <- as(x, 'CsparseMatrix')
    object@raw.data <- lapply(object@raw.data, function(x) {
      as(x, 'CsparseMatrix')
    })
  }
  raw.data <- MergeSparseDataAll(object@raw.data, nms)
  scale.data <- do.call(rbind, object@scale.data)
  rownames(scale.data) <- colnames(raw.data)
  if (maj_version < 3) {
    var.genes <- object@var.genes
    inmf.obj <- new(
      Class = "dim.reduction", gene.loadings = t(object@W),
      cell.embeddings = object@H.norm, key = "iNMF_"
    )
    rownames(inmf.obj@gene.loadings) <- var.genes
    tsne.obj <- new(
      Class = "dim.reduction", cell.embeddings = object@dr.coords[["tsne"]],
      key = "tSNE_"
    )
  } else {
    var.genes <- object@var.genes
    if (any(grepl('_', var.genes))) {
      print("Warning: Seurat v3 genes cannot have underscores, replacing with dashes ('-')")
      var.genes <- gsub("_", replacement = "-", var.genes)
    }
    inmf.obj <- new(
      Class = "DimReduc", feature.loadings = t(object@W),
      cell.embeddings = object@H.norm, key = "iNMF_"
    )
    rownames(inmf.obj@feature.loadings) <- var.genes
    tsne.obj <- new(
      Class = "DimReduc", cell.embeddings = object@dr.coords[["tsne"]],
      key = "tSNE_"
    )
  }
  rownames(tsne.obj@cell.embeddings) <- rownames(scale.data)
  rownames(inmf.obj@cell.embeddings) <- rownames(scale.data)
  colnames(tsne.obj@cell.embeddings) <- paste0("tSNE_", 1:2)
  new.seurat <- Seurat::CreateSeuratObject(raw.data)
  if (renormalize) {
    new.seurat <- Seurat::NormalizeData(new.seurat)
  }
  if (by.dataset) {
    ident.use <- as.character(unlist(lapply(1:length(object@raw.data), function(i) {
      dataset.name <- names(object@raw.data)[i]
      paste0(dataset.name, as.character(object@clusters[colnames(object@raw.data[[i]])]))
    })))
  } else {
    ident.use <- as.character(object@clusters)
  }

  if (maj_version < 3) {
    if (use.liger.genes) {
      new.seurat@var.genes <- var.genes
    }
    new.seurat@scale.data <- t(scale.data)
    new.seurat@dr$tsne <- tsne.obj
    new.seurat@dr$inmf <- inmf.obj
    new.seurat <- SetIdent(new.seurat, ident.use = ident.use)

  } else {
    if (use.liger.genes) {
      new.seurat@assays$RNA@var.features <- var.genes
    }
    Seurat::SetAssayData(new.seurat, slot = "scale.data",  t(scale.data), assay = "RNA")
    new.seurat@reductions$tsne <- tsne.obj
    new.seurat@reductions$inmf <- inmf.obj

    Idents(new.seurat) <- ident.use
  }

  return(new.seurat)
}

#' Create liger object from one or more Seurat objects
#'
#' This function creates a \code{liger} object from multiple (disjoint) Seurat objects or a single
#' (combined-analysis) Seurat object. It includes options for keeping the variable genes and cluster
#' identities from the original Seurat objects. Seurat V2 and V3 supported (though all objects
#' should share the same major version).
#'
#' @param objects One or more Seurat v2 objects. If passing multiple objects, should be in list.
#' @param combined.seurat Whether Seurat object (single) already contains multiple datasets (default
#'   FALSE).
#' @param names Names to use for datasets in new liger object. If use-projects, takes project names
#'   from individual Seurat objects; if use-meta, takes value of object meta.data in meta.var column
#'   for each dataset; otherwise, user can pass in vector of names with same length
#'   as number of datasets. If combined.seurat, infers project names based on whether meta.var
#'   or assays.use is present (at least one required).
#' @param meta.var Seurat meta.data column name to use in naming datasets. Either meta.var or
#'   assays.use required if combined.seurat is TRUE (default NULL).
#' @param assays.use Names of Seurat v3 assays to use as separate datasets in conversion (e.g. RNA,
#'   ADT) (default NULL).
#' @param raw.assay Name of Seurat v3 assay to use for raw data if meta.var used to split combined
#'   Seurat object -- in case integrated assay has been set as default (default "RNA").
#' @param remove.missing Whether to remove missing genes/cells when converting raw.data to liger object
#'   (default TRUE).
#' @param renormalize Whether to automatically normalize raw.data once \code{liger} object is created
#'   (default TRUE).
#' @param use.seurat.genes Carry over variable genes from Seurat objects. If num.hvg.info is set, uses
#'   that value to get top most highly variable genes from hvg.info slot in Seurat objects. Otherwise
#'   uses var.genes slot in Seurat objects. For multiple datasets, takes the union of the variable
#'   genes. (default TRUE)
#' @param num.hvg.info Number of highly variable genes to include from each object's hvg.info slot.
#'   Only available for Seurat v2 objects. If set, recommended value is 2000 (default NULL).
#' @param use.idents Carry over cluster identities from Seurat objects. If multiple objects with
#'   overlapping cluster names, will preface cluster names by dataset names to distinguish. (default
#'   TRUE).
#' @param use.tsne Carry over t-SNE coordinates from Seurat object (only meaningful for combined
#'   analysis Seurat object). Useful for plotting directly afterwards. (default TRUE)
#' @param cca.to.H Carry over CCA (and aligned) loadings and insert them into H (and H.norm) slot in
#'   liger object (only meaningful for combined analysis Seurat object). Useful for plotting directly
#'   afterwards. (default FALSE)

#' @return \code{liger} object.
#' @export
#' @examples
#' \dontrun{
#' # Seurat objects for two pbmc datasets
#' tenx <- readRDS('tenx.RDS')
#' seqwell <- readRDS('seqwell.RDS')
#' # create liger object, using project names
#' ligerex <- seuratToLiger(list(tenx, seqwell))
#' # create liger object, passing in names explicitly, using hvg.info genes
#' ligerex2 <- seuratToLiger(list(tenx, seqwell), names = c('tenx', 'seqwell'), num.hvg.info = 2000)
#' # Seurat object for joint analysis
#' pbmc <- readRDS('pbmc.RDS')
#' # create liger object, using 'protocol' for dataset names
#' ligerex3 <- seuratToLiger(pbmc, combined.seurat = T, meta.var = 'protocol', num.hvg.info = 2000)
#' }

seuratToLiger <- function(objects, combined.seurat = F, names = "use-projects", meta.var = NULL,
                          assays.use = NULL, raw.assay = "RNA", remove.missing = T, renormalize = T,
                          use.seurat.genes = T, num.hvg.info = NULL, use.idents = T, use.tsne = T,
                          cca.to.H = F) {

  # Remind to set combined.seurat
  if ((typeof(objects) != "list") & (!combined.seurat)) {
    stop("Please pass a list of objects or set combined.seurat = T")
  }
  # Get Seurat versions
  if (typeof(objects) != "list") {
    version <- package_version(objects@version)$major
  } else {
    version <- sapply(objects, function(x) {
      package_version(x@version)$major
    })
    if (min(version) != max(version)) {
      stop("Please ensure all Seurat objects have the same major version.")
    } else {
      version <- version[1]
    }
  }

  # Only a single seurat object expected if combined.seurat
  if (combined.seurat) {
    if ((is.null(meta.var)) & (is.null(assays.use))) {
      stop("Please provide Seurat meta.var or assays.use to use in identifying individual datasets.")
    }
    if (!is.null(meta.var)) {
      # using meta.var column as division split
      if (version > 2) {
        # if integrated assay present, want to make sure to use original raw data
        object.raw <- GetAssayData(objects, assay = raw.assay, slot = "counts")
      } else {
        object.raw <- objects@raw.data
      }
      if (nrow(objects@meta.data) != ncol(object.raw)) {
        cat("Warning: Mismatch between meta.data and raw.data in this Seurat object. \nSome cells",
            "will not be assigned to a raw dataset. \nRepeat Seurat analysis without filters to",
            "allow all cells to be assigned.\n")
      }
      raw.data <- lapply(unique(objects@meta.data[[meta.var]]), function(x) {
        cells <- rownames(objects@meta.data[objects@meta.data[[meta.var]] == x, ])
        object.raw[, cells]
      })
      names(raw.data) <- unique(objects@meta.data[[meta.var]])
    } else {
      # using different assays in v3 object
      raw.data <- lapply(assays.use, function(x) {
        GetAssayData(objects, assay = x, slot = "counts")
      })
      names(raw.data) <- assays.use
    }

    if (version > 2) {
      var.genes <- VariableFeatures(objects)
      idents <- Idents(objects)
      if (is.null(objects@reductions$tsne)) {
        cat("Warning: no t-SNE coordinates available for this Seurat object.\n")
        tsne.coords <- NULL
      } else {
        tsne.coords <- objects@reductions$tsne@cell.embeddings
      }
    } else {
      # Get var.genes
      var.genes <- objects@var.genes
      # Get idents/clusters
      idents <- objects@ident
      # Get tsne.coords
      if (is.null(objects@dr$tsne)) {
        cat("Warning: no t-SNE coordinates available for this Seurat object.\n")
        tsne.coords <- NULL
      } else {
        tsne.coords <- objects@dr$tsne@cell.embeddings
      }
    }
  } else {
    # for multiple Seurat objects
    raw.data <- lapply(objects, function(x) {
      if (version > 2) {
        # assuming default assays have been set for each v3 object
        GetAssayData(x, slot = "counts")
      } else {
        x@raw.data
      }
    })
    names(raw.data) <- lapply(seq_along(objects), function(x) {
      if (identical(names, "use-projects")) {
        if (!is.null(meta.var)) {
          cat("Warning: meta.var value is set - set names = 'use-meta' to use meta.var for names.\n")
        }
        objects[[x]]@project.name
      } else if (identical(names, "use-meta")) {
        if (is.null(meta.var)) {
          stop("Please provide meta.var to use in naming individual datasets.")
        }
        objects[[x]]@meta.data[[meta.var]][1]
      } else {
        names[x]
      }
    })
    # tsne coords not very meaningful for separate objects
    tsne.coords <- NULL

    if (version > 2) {
      var.genes <- Reduce(union, lapply(objects, function(x) {
        VariableFeatures(x)
      }))
      # Get idents, label by dataset
      idents <- unlist(lapply(seq_along(objects), function(x) {
        idents <- rep("NA", ncol(raw.data[[x]]))
        names(idents) <- colnames(raw.data[[x]])
        idents[names(Idents(objects[[x]]))] <- as.character(Idents(objects[[x]]))
        idents <- paste0(names(raw.data)[x], idents)
      }))
      idents <- factor(idents)
    } else {
      var.genes <- Reduce(union, lapply(objects, function(x) {
        if (!is.null(num.hvg.info)) {
          rownames(head(x@hvg.info, num.hvg.info))
        } else {
          x@var.genes
        }
      }))
      # Get idents, label by dataset
      idents <- unlist(lapply(seq_along(objects), function(x) {
        idents <- rep("NA", ncol(objects[[x]]@raw.data))
        names(idents) <- colnames(objects[[x]]@raw.data)
        idents[names(objects[[x]]@ident)] <- as.character(objects[[x]]@ident)
        idents <- paste0(names(raw.data)[x], idents)
      }))
      idents <- factor(idents)
    }
  }
  new.liger <- createLiger(raw.data = raw.data, remove.missing = remove.missing)
  if (renormalize) {
    new.liger <- normalize(new.liger)
  }
  if (use.seurat.genes) {
    # Include only genes which appear in all datasets
    for (i in 1:length(new.liger@raw.data)) {
      var.genes <- intersect(var.genes, rownames(new.liger@raw.data[[i]]))
      # Seurat has an extra CheckGenes step which we can include here
      # Remove genes with no expression anywhere
      var.genes <- var.genes[rowSums(new.liger@raw.data[[i]][var.genes, ]) > 0]
      var.genes <- var.genes[!is.na(var.genes)]
    }

    new.liger@var.genes <- var.genes
  }
  if (use.idents) {
    new.liger@clusters <- idents
  }
  if ((use.tsne) & (!is.null(tsne.coords))) {
    new.liger@dr.coords[[dr.method]] <- tsne.coords
  }
  # Get CCA loadings if requested
  if (cca.to.H & combined.seurat) {
    if (version > 2) {
      cat("Warning: no CCA loadings available for Seurat v3 objects.\n")
      return(new.liger)
    }
    if (is.null(objects@dr$cca)) {
      cat("Warning: no CCA loadings available for this Seurat object.\n")
    } else {
      new.liger@H <- lapply(unique(objects@meta.data[[meta.var]]), function(x) {
        cells <- rownames(objects@meta.data[objects@meta.data[[meta.var]] == x, ])
        objects@dr$cca@cell.embeddings[cells, ]
      })
      new.liger@H <- lapply(seq_along(new.liger@H), function(x) {
        addMissingCells(new.liger@raw.data[[x]], new.liger@H[[x]])
      })
      names(new.liger@H) <- names(new.liger@raw.data)
    }
    if (is.null(objects@dr$cca.aligned)) {
      cat("Warning: no aligned CCA loadings available for this Seurat object.\n")
    } else {
      new.liger@H.norm <- objects@dr$cca.aligned@cell.embeddings
      new.liger@H.norm <- addMissingCells(Reduce(rbind, new.liger@H), new.liger@H.norm,
                                          transpose = T)
    }
  }
  return(new.liger)
}

#' Construct a liger object with a specified subset
#'
#' The subset can be based on cell names or clusters. This function applies the subsetting to
#' raw.data, norm.data, scale.data, cell.data, H, W, V, H.norm, tsne.coords, and clusters.
#' Note that it does NOT reoptimize the factorization. See optimizeSubset for this functionality.
#'
#' @param object \code{liger} object. Should run quantileAlignSNF and runTSNE before calling.
#' @param clusters.use Clusters to use for subset.
#' @param cells.use Vector of cell names to keep from any dataset.
#' @param remove.missing Whether to remove genes/cells with no expression when creating new object
#'   (default TRUE).
#'
#' @return \code{liger} object with subsetting applied to raw.data, norm.data, scale.data, H, W, V,
#'   H.norm, tsne.coords, and clusters.
#' @export
#' @examples
#' \dontrun{
#' # liger object, with clusters 0:10
#' # factorization, alignment, and t-SNE calculation have been performed
#' ligerex
#' # subset by clusters
#' ligerex_subset <- subsetLiger(ligerex, clusters.use = c(1, 4, 5))
#' }

subsetLiger <- function(object, clusters.use = NULL, cells.use = NULL, remove.missing = T) {
  if (!is.null(clusters.use)) {
    cells.use <- names(object@clusters)[which(object@clusters %in% clusters.use)]
  }
  raw.data <- lapply(seq_along(object@raw.data), function(q) {
    cells <- intersect(cells.use, colnames(object@raw.data[[q]]))
    if (length(cells) > 0) {
      object@raw.data[[q]][, cells]
    } else {
      warning(paste0("Selected subset eliminates dataset ", names(object@raw.data)[q]))
      return(NULL)
    }
  })
  missing <- sapply(raw.data, is.null)
  raw.data <- raw.data[!missing]
  nms <- names(object@raw.data)[!missing]
  names(raw.data) <- nms
  a <- createLiger(raw.data, remove.missing = remove.missing)
  # Add back additional cell.data
  if (ncol(a@cell.data) < ncol(object@cell.data)) {
    a@cell.data <- droplevels(data.frame(object@cell.data[cells.use, ]))
  }
  a@norm.data <- lapply(1:length(a@raw.data), function(i) {
    object@norm.data[[nms[i]]][, colnames(a@raw.data[[i]])]
  })
  a@scale.data <- lapply(1:length(a@raw.data), function(i) {
    object@scale.data[[nms[i]]][colnames(a@raw.data[[i]]), ]
  })
  a@H <- lapply(1:length(a@raw.data), function(i) {
    object@H[[nms[i]]][colnames(a@raw.data[[i]]), ]
  })
  a@clusters <- object@clusters[unlist(lapply(a@H, rownames))]
  a@clusters <- droplevels(a@clusters)
  a@dr.coords[["tsne"]] <- object@dr.coords[["tsne"]][names(a@clusters), ]
  a@dr.coords[["umap"]] <- object@dr.coords[["umap"]][names(a@clusters), ]
  a@H.norm <- object@H.norm[names(a@clusters), ]
  a@W <- object@W
  a@V <- object@V
  a@var.genes <- object@var.genes
  names(a@scale.data) <- names(a@norm.data) <- names(a@H) <- nms
  return(a)
}

#' Convert older liger object into most current version (based on class definition)
#'
#' Also works for Analogizer objects (but must have both liger and Analogizer loaded). Transfers
#' data in slots with same names from old class object to new, leaving slots defined only in new
#' class NULL.
#'
#' @param object \code{liger} object.
#' @param override.raw Keep original raw.data without any modifications (removing missing cells
#'   etc.) (defualt FALSE).
#'
#' @return Updated \code{liger} object.
#' @export
#' @examples
#' \dontrun{
#' # old Analogizer object
#' analogy
#' # convert to latest class definition
#' ligerex <- convertOldLiger(analogy)
#' }

convertOldLiger = function(object, override.raw = F) {
  new.liger <- createLiger(object@raw.data)
  slots_new <- slotNames(new.liger)
  slots_old <- slotNames(object)
  slots_exist <- sapply(slots_new, function(x) {
    .hasSlot(object, x)
  })

  slots <- slots_new[slots_exist]
  for (slotname in slots) {
    if (!(slotname %in% c('raw.data')) | (override.raw)) {
      slot(new.liger, slotname) <- slot(object, slotname)
    }
  }
  print(paste0('Old slots not transferred: ', setdiff(slots_old, slots_new)))
  # compare to slots since it's possible that the analogizer object
  # class has slots that this particular object does not
  print(paste0('New slots not filled: ', setdiff(slots_new[slots_new != "cell.data"], slots)))
  return(new.liger)
}
